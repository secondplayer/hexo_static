<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    <link rel="canonical" href="http://secondplayer.top/2018/04/30/machine-learning-svm-part-two/">
    
    
    <title>机器学习笔记7: 支持向量机(下) | SecondPlayer&#39;s Blog | 我读书多，你别骗我</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="机器学习">
    <meta name="description" content="上一篇文章中我们已经根据拉格朗日对偶性推导出了SVM最优化公式。而在这一篇文章中，我们将会从SVM最优化公式中引出核函数(kernels)的概念，由此给出在高维空间下更高效应用SVM的算法，然后利用正则化解决线性不可分与异常点的问题，最后介绍用于高效实现SVM的序列最小优化(sequential minimal optimization)算法。 核函数在线性回归的问题中，我们曾举过预测房价的例子，">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记7: 支持向量机(下)">
<meta property="og:url" content="http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/index.html">
<meta property="og:site_name" content="SecondPlayer&#39;s Blog">
<meta property="og:description" content="上一篇文章中我们已经根据拉格朗日对偶性推导出了SVM最优化公式。而在这一篇文章中，我们将会从SVM最优化公式中引出核函数(kernels)的概念，由此给出在高维空间下更高效应用SVM的算法，然后利用正则化解决线性不可分与异常点的问题，最后介绍用于高效实现SVM的序列最小优化(sequential minimal optimization)算法。 核函数在线性回归的问题中，我们曾举过预测房价的例子，">
<meta property="og:locale" content="zh">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-c13233913129da02.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-05259e57b49c6150.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-6c74ef39e35acdba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-a2e6188faa3f6b14.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-f80f518523d72047.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-a0b575380c3efeb6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-21c0bf270d1412e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-8c4c2471c88f0967.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-893a75241ac69a7b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-eab251efa23c1d18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-b66c3dfc0b3f73cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-95bfcba57166ba50.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-47692cc3a15b82a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-a95b5e7847f4eb83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-a77dc740f51cc305.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-138f74c6b2f226df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-f90a8e77cb13a78d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-17ff5cd08b11019d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-f3afdff51d8224b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-b4d05b184ebd2b41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-9a09217189f988c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-bb384100c09a9ee0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-f7f5b44e54e98008.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-fd39699dbc777c6b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-991e01e70893e605.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/2245716-46f5629d2ed03e87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2018-04-30T12:39:28.786Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习笔记7: 支持向量机(下)">
<meta name="twitter:description" content="上一篇文章中我们已经根据拉格朗日对偶性推导出了SVM最优化公式。而在这一篇文章中，我们将会从SVM最优化公式中引出核函数(kernels)的概念，由此给出在高维空间下更高效应用SVM的算法，然后利用正则化解决线性不可分与异常点的问题，最后介绍用于高效实现SVM的序列最小优化(sequential minimal optimization)算法。 核函数在线性回归的问题中，我们曾举过预测房价的例子，">
<meta name="twitter:image" content="https://upload-images.jianshu.io/upload_images/2245716-c13233913129da02.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
    
        <link rel="alternate" type="application/atom+xml" title="SecondPlayer&#39;s Blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/gravatar.png">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">secondplayer</h5>
          <a href="mailto:secondplayer1990@gmail.com" title="secondplayer1990@gmail.com" class="mail">secondplayer1990@gmail.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/secondplayer" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="http://www.weibo.com/1901978451" target="_blank" >
                <i class="icon icon-lg icon-weibo"></i>
                Weibo
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">机器学习笔记7: 支持向量机(下)</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">机器学习笔记7: 支持向量机(下)</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-04-30T12:39:28.000Z" itemprop="datePublished" class="page-time">
  2018-04-30
</time>


            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#核函数"><span class="post-toc-number">1.</span> <span class="post-toc-text">核函数</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#正则化与线性不可分的情况"><span class="post-toc-number">2.</span> <span class="post-toc-text">正则化与线性不可分的情况</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#坐标上升算法"><span class="post-toc-number">3.</span> <span class="post-toc-text">坐标上升算法</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#序列最小优化算法"><span class="post-toc-number">4.</span> <span class="post-toc-text">序列最小优化算法</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#总结"><span class="post-toc-number">5.</span> <span class="post-toc-text">总结</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#参考资料"><span class="post-toc-number">6.</span> <span class="post-toc-text">参考资料</span></a></li></ol>
        </nav>
    </aside>


<article id="post-machine-learning-svm-part-two"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">机器学习笔记7: 支持向量机(下)</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-04-30 20:39:28" datetime="2018-04-30T12:39:28.000Z"  itemprop="datePublished">2018-04-30</time>

            


            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>上一篇文章中我们已经根据拉格朗日对偶性推导出了SVM最优化公式。而在这一篇文章中，我们将会从SVM最优化公式中引出<strong>核函数</strong>(kernels)的概念，由此给出在高维空间下更高效应用SVM的算法，然后利用正则化解决线性不可分与异常点的问题，最后介绍用于高效实现SVM的<strong>序列最小优化</strong>(sequential minimal optimization)算法。</p>
<h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>在线性回归的问题中，我们曾举过预测房价的例子，输入特征x是住房面积。假设我们为了提高预测准确性，希望用x<sup>2</sup>，x<sup>3</sup>作为特征来建模。为了区别这两类变量，我们把原始的输入变量称为<strong>属性</strong>(attribute)，对原始变量映射后的项叫做<strong>特征</strong>(feature)。定义φ为<strong>特征映射</strong>(feature mapping)函数，在这个例子中，我们有：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-c13233913129da02.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>为了应用SVM算法，我们需要将算法中出现x的地方替换成φ(x)。由于算法可以被完全写成向量内积的形式<x, z="">，这意味着我们可以将其替换为&lt;φ(x), φ(z)&gt;。给定一个特征映射函数，我们定义<strong>核函数</strong>(kernels)为：</x,></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-05259e57b49c6150.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>因此，在算法中我们可以把<x, z="">都替换成K(x, z)。给定φ，我们通过求φ(x)和φ(z)的内积来计算K(x, z)。有趣的是，即使φ(x)可能因为维度较高导致计算起来比较耗时，而计算K(x, z)并不是很耗时。在这种情况下，通过在算法中引入K(x, z)，可以使得SVM算法的计算量大大减少。</x,></p>
<p>我们来举个例子看一下，假设</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-6c74ef39e35acdba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们可以计算出：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-a2e6188faa3f6b14.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>对比K(x, z)的定义，可得到特征映射函数φ为(当n=3时)：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-f80f518523d72047.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>可见计算φ(x)的时间复杂度是O(n<sup>2</sup>)，而计算K(x, z)的时间复杂度是O(n)。</p>
<p>再考虑一个例子，假设</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-a0b575380c3efeb6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>对比K(x, z)的定义，可得到特征映射函数φ为(当n=3时)：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-21c0bf270d1412e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>推广到更一般的形式，假设K(x, z) = (x<sup>T</sup>z + c)<sup>d</sup>，计算φ(x)的时间复杂度是O(n<sup>d</sup>)，而计算K(x, z)的时间复杂度仍旧是O(n)。当维度较高时，核函数的优势更加明显。</p>
<p>另一个常用的核函数是<strong>高斯核</strong>(Gaussian kernel)，其特征映射函数φ可以映射到无限维。高斯核函数为：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-8c4c2471c88f0967.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们接下来的一个问题就是给定一个函数K，它是否能成为一个合法的核函数，也就是说是否存在一个映射函数φ使得K(x, z) = &lt;φ(x), φ(z)&gt;? </p>
<p>假设K是一个合法的核函数，对于一个包含有限个点的集合{x<sup>(1)</sup>, x<sup>(2)</sup>, …, x<sup>(m)</sup>}，定义<strong>核矩阵</strong>(Kernel matrix)K，矩阵的每个元素K<sub>ij</sub> = K(x<sup>(i)</sup>, x<sup>(j)</sup>)。注意由于核函数和核矩阵的关系密切，我们使用了相同的符号K来表示它们。</p>
<p>当K是合法的核函数时，可证明K<sub>ij</sub> = K<sub>ji</sub>，因此K是对称矩阵。此外，定义φ<sub>k</sub>(x)表示向量φ(x)的第k个元素，我们也能证明：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-893a75241ac69a7b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>综上我们可得出结论，如果K是合法的核函数，那么对应的核矩阵K是<strong>对称半正定</strong>(symmetric positive semidefinite)矩阵。这个结论反过来也成立，即“K是合法的核函数”是“核矩阵K是对称半正定矩阵”的充分必要条件，这个结论被称为<strong>Mercer定理</strong>(Mercer Theorem)。</p>
<p>核函数在机器学习中有广泛的应用。比如在数字识别问题中，我们需要根据一张图片(16*16像素)识别出数字(0-9)。如果把每个像素作为特征值，那么会有256个特征值，使用核函数(K(x, z) = (x<sup>T</sup>z)<sup>d</sup>或者高斯核)后可以使SVM的性能大大提升。</p>
<h2 id="正则化与线性不可分的情况"><a href="#正则化与线性不可分的情况" class="headerlink" title="正则化与线性不可分的情况"></a>正则化与线性不可分的情况</h2><p>到目前为止，我们在推导SVM过程中都是基于“数据是线性可分的”这个假设。尽管用函数φ将特征映射到高维可以增加数据线性可分的可能性，但这个假设不能保证总是成立。此外，还有一种情况是如果数据里有<strong>异常点</strong>(outlier)，那么得到的超平面可能并不是我们想要的结果。比如左下图显示了一个最优超平面，右下图里增加了一个异常点使得最优超平面的间隔变小了，影响了分类器的性能。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-eab251efa23c1d18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>为了使SVM算法在线性不可分的情况下正常工作，并且对异常点不那么敏感，我们采用<strong>l1正则化</strong>(l1 regularization)方法修改优化目标为： </p>
<p><img src="https://upload-images.jianshu.io/upload_images/2245716-b66c3dfc0b3f73cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>通过增加ξ<sub>i</sub>项，我们允许函数间隔小于1，并且当函数间隔小于1的时候，我们在目标函数增加Cξ<sub>i</sub>的代价。</p>
<p>同样，我们对该问题构造拉格朗日算子：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-95bfcba57166ba50.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>其中α<sub>i</sub>和r<sub>i</sub>是拉格朗日乘数。我们不详细展开推导了，最后我们可以得到对偶问题为：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-47692cc3a15b82a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通过求解该最大化问题可以得到α<sup>*</sup>，然后代入回原始问题可得到其他参数。另外由于采用了l1正则化，原来α<sub>i</sub> &gt;= 0的限制变成了 0 &lt;= α<sub>i</sub> &lt;= C。此外，该问题的KKT对偶互补条件为：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-a95b5e7847f4eb83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>最后我们还剩下一个问题没有讲，那就是如何求解最大化W(α)的方法，这个是我们下面要介绍的内容。</p>
<h2 id="坐标上升算法"><a href="#坐标上升算法" class="headerlink" title="坐标上升算法"></a>坐标上升算法</h2><p>首先我们考虑没有任何约束条件的优化问题：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-a77dc740f51cc305.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>其中W是以α为参数的函数。之前在优化问题中我们介绍过梯度下降法和牛顿方法，在这个问题里我们使用<strong>坐标上升</strong>(coordinate ascent)算法。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-138f74c6b2f226df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>算法的核心思想是，每次固定一个参数α<sub>i</sub>，然后使W关于α<sub>i</sub>作优化调整。在这个算法里，我们依次选取α<sub>1</sub>到α<sub>m</sub>作优化，然后不断循环直到结果收敛为止。这个算法的一个优化方向是，调整α<sub>i</sub>参数选取的顺序，每次选择使得W(α)增加幅度最大的α<sub>i</sub>作为下一个参数。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-f90a8e77cb13a78d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>上图是一个优化二次函数的等高线示意图。坐标初始点在(-2, 2)，可以看到每次优化只在一个维度方向上进行优化。</p>
<h2 id="序列最小优化算法"><a href="#序列最小优化算法" class="headerlink" title="序列最小优化算法"></a>序列最小优化算法</h2><p>回到我们SVM的对偶问题上来，我们要求解的优化问题为：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-17ff5cd08b11019d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用坐标上升算法的思想，我们每次固定一个参数α<sub>i</sub>进行优化是否可行？答案是不可行，假设我们固定α<sub>1</sub>，根据约束条件(19)，可得：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-f3afdff51d8224b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>两边都乘以y<sup>(1)</sup>，可得：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-b4d05b184ebd2b41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>所以α<sub>1</sub>受到其余α<sub>i</sub>参数的控制，当α<sub>2</sub>, …, α<sub>m</sub>不变时，α<sub>1</sub>也不会改变。</p>
<p>因此如果我们要使用坐标上升算法的话，需要一次更新两个参数。具体来说就是，每次选取两个参数α<sub>i</sub>和α<sub>j</sub>进行更新，使W关于α<sub>i</sub>和α<sub>j</sub>作优化调整，然后不断循环直到结果收敛为止。</p>
<p>这个算法被称为<strong>序列最小优化</strong>(sequential minimal optimization, SMO)算法，最早由<a href="https://en.wikipedia.org/wiki/John_Platt_(computer_scientist" target="_blank" rel="external">John Platt</a>)提出，相关论文可以在<a href="https://www.microsoft.com/en-us/research/publication/sequential-minimal-optimization-a-fast-algorithm-for-training-support-vector-machines/" target="_blank" rel="external">这里</a>找到。</p>
<p>为了判断算法的收敛性，我们可以检查KKT条件是否满足tol参数，具体方法在John Platt关于SMO的论文里有阐述。</p>
<p>SMO算法之所以高效就在于每次更新两个参数α<sub>i</sub>和α<sub>j</sub>的操作本身就很高效，我们具体来描述一下。</p>
<p>根据等式(19)，我们有：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-9a09217189f988c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>既然等式右边的参数是固定的，我们就用一个常量ζ来表示：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-bb384100c09a9ee0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们可以把α<sub>1</sub>和α<sub>2</sub>的约束条件画成下面的图。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-f7f5b44e54e98008.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>根据约束条件(18)，α<sub>1</sub>和α<sub>2</sub>必须限制在[0,C]×[0,C]的方块内。另外α<sub>1</sub>和α<sub>2</sub>必须满足图中直线的约束。α<sub>2</sub>要满足L ≤ α<sub>2</sub> ≤ H的条件，其中L, H是α<sub>2</sub>的上下边界。</p>
<p>根据等式(20)，我们把α<sub>1</sub>写成是关于α<sub>2</sub>的函数:</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-fd39699dbc777c6b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>那么目标函数W可以表示为：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-991e01e70893e605.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>把α<sub>3</sub>, …, α<sub>m</sub>视为常量，可以看出W是关于α<sub>2</sub>的二次函数。如果我们不考虑限制条件(18)，那么通过求导就可以求出使这个二次函数最大化的参数，记为α<sub>2</sub><sup>new, unclipped</sup>。再把限制条件(18)考虑进来，我们可以得到：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://upload-images.jianshu.io/upload_images/2245716-46f5629d2ed03e87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>最后，根据α<sub>2</sub><sup>new</sup>的值以及等式(20)，可以求得α<sub>1</sub><sup>new</sup>的值。</p>
<p>关于这个算法还有其他一些细节，但我们不会在这里一一阐述，有兴趣的读者可以自行查看Platt的论文。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>引入核函数的概念后，通过把数据映射到高维空间，有概率可解决原始空间中线性不可分的问题，并且可以使SVM算法更高效</li>
<li>Mercer定理：“一个核函数是合法的”是“核函数对应的核矩阵是对称半正定矩阵”的充分必要条件</li>
<li>为了使SVM算法在线性不可分的情况下正常工作，并且对异常点不那么敏感，可以采用l1正则化的方法</li>
<li>John Platt提出的SMO算法，可以高效求解SVM的对偶问题，其基本思想是利用了坐标上升算法</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li>斯坦福大学机器学习课CS229讲义 <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="external">pdf</a></li>
<li>网易公开课：机器学习课程 <a href="https://open.163.com/movie/2008/1/9/3/M6SGF6VB4_M6SGJVA93.html" target="_blank" rel="external">双语字幕视频</a></li>
</ul>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2018-04-30T12:39:28.786Z" itemprop="dateUpdated">2018-04-30 20:39:28</time>
</span><br>


        
        <a href="/2018/04/30/machine-learning-svm-part-two/" target="_blank" rel="external">http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/</a>
        
    </div>
    
    <footer>
        <a href="http://www.secondplayer.top">
            <img src="/img/gravatar.png" alt="secondplayer">
            secondplayer
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/&title=《机器学习笔记7: 支持向量机(下)》 — SecondPlayer's Blog&pic=http://www.secondplayer.top/img/gravatar.png" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/&title=《机器学习笔记7: 支持向量机(下)》 — SecondPlayer's Blog&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《机器学习笔记7: 支持向量机(下)》 — SecondPlayer's Blog&url=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/&via=http://www.secondplayer.top" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/04/15/machine-learning-svm-part-one/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">机器学习笔记6: 支持向量机(上)</h4>
      </a>
    </div>
  
</nav>



    











    <!-- Valine Comments -->
    <div class="comments vcomment" id="comments"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
    <!-- Valine Comments script -->
    <script>
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail,link'.split(',').filter(function(item){
          return GUEST_INFO.indexOf(item) > -1
        });
        new Valine({
            el: '#comments',
            notify: 'false' == 'true',
            verify: 'false' == 'true',
            appId: "9Igi0ekMnJy1GPd4IP3n1AvX-gzGzoHsz",
            appKey: "4YLq9PqAFlVgrofe0MbTQ746",
            avatar: "",
            placeholder: "Just say something",
            guest_info: guest_info.length == 0 ? GUEST_INFO : guest_info,
            pageSize: "10"
        })
    </script>
    <!-- Valine Comments end -->




</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢大爷~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat_pay_minicode.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat_pay_minicode.jpg" data-alipay="/img/alipay_qrcode.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>secondplayer &copy; 2016 - 2018</span>
            <span>
                
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/&title=《机器学习笔记7: 支持向量机(下)》 — SecondPlayer's Blog&pic=http://www.secondplayer.top/img/gravatar.png" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/&title=《机器学习笔记7: 支持向量机(下)》 — SecondPlayer's Blog&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《机器学习笔记7: 支持向量机(下)》 — SecondPlayer's Blog&url=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/&via=http://www.secondplayer.top" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://www.secondplayer.top/2018/04/30/machine-learning-svm-part-two/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACwElEQVR42u3a0W7DMAgF0Pz/T2+vnba4F7CrTDp5mrrW8UkloODriq+vl+v3K3evv77y++/1f9frbL7w8PDwBltPNn13m7utr0nrd+YP93YFPDw8vGO89XbXQTkP/cln14843zMeHh7ec3hJWbwO9EkBnSQGPDw8vP/CS4rjvGHRa0bg4eHhPYHXK2eTUF5dJ3/cm3steHh4eDEvnyI95+8j8z08PDy88VQ9Ce57Q3ZeZEe7xcPDwzvAywNuvukcNmlG5A8IDw8P7wSv+rN/nR5ycH6Uag2uHlbAw8PDm/Amgbi6xXlruPD9zPMMHh4eXvGteemcB/TTyePNfA8PDw/vGC9JBuvEUGVU77ttdoeHh4d3+KxRr00warbOh214eHh4x3hVZF4o52X6PEncFtN4eHh4W3nJYCkPzclG8wdRHYnh4eHhfZKX3z4/PtU7XNVrOhRSFB4eHt4mXhL6k+ZsnhgmaaZ8IAwPDw/vAK86oKoC5m3ivMFx9T6Ah4eHN+BVb58fIEgK7t77q0M1PDw8vAmvutHe2CzvqfYe0O2aeHh4eB/knRiD5U2E3tGuN4eu8PDw8Dbx8pbBpBTOU0heoBcOXeHh4eEd4O0N00lZ3GttNM9T4eHh4R3g5Smh17rNV07SVe9wAx4eHt4J3unDBPNB1yQ54eHh4e3l5cG611bordA71nDlOQcPDw9vzKsWqUkymBfivUEaHh4e3id51RFUstFRWJ9feHh4eB+E5QG6lyryxkf+OH78Fw8PD+8Abx5jq0Os/IBC3jg+mELw8PDwBiX1ZEyVBO5zDWI8PDy8c7xk1FQN9NVjWPNs9scKeHh4eI/hVcvove8vPCA8PDy8B/Dyxm6eVJL1k4R05d8AHh4e3piX3zJv4ybjqF47uDAYw8PDwzvAq/7Iz5erjsSqKWTzfA8PDw/v/fUNrwjaT7ESXV0AAAAASUVORK5CYII=" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


lazyScripts.push('//s95.cnzz.com/z_stat.php?id=1259512342&web_id=1259512342')

</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>






<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
