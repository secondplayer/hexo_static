[{"title":"常见推荐系统介绍","date":"2017-09-07T16:07:37.000Z","path":"2017/09/08/recommendation-system-book/","text":"本文主要是对项亮的推荐系统实践部分章节进行了一些总结，先从什么是推荐系统开始讲起，然后介绍了评测推荐系统的指标和方法，最后介绍了常见的推荐系统算法。 《推荐系统实践》封面 什么是推荐系统随着信息技术和互联网的快速发展，人们逐渐从信息匮乏的时代走入了信息过载的时代。每天都有海量的信息被生产出来，用户如何从中找到自己感兴趣的内容变得越来越困难，内容生产者也在想方设法让自己生成的内容从海量信息中脱颖而出。为了解决信息过载的问题，历史上出现过的代表方案有分类目录和搜索引擎，这两者都要求用户明确知道自己需要的内容关键词。而推荐系统不需要用户提供明确的需求，而是通过分析用户的历史行为给用户的兴趣建模，从而主动给用户推荐能够满足它们兴趣的内容。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户，帮助用户发现那些他们感兴趣但很难发现的商品。 推荐系统的应用在互联网的各类网站中都可以看到推荐系统的应用，尽管不同网站使用的技术不同，但总的来说几乎所有的推荐系统应用都是由前台的展示页面、后台的日志系统以及推荐算法系统构成。 电子商务：淘宝、京东、亚马逊 电影/视频：Netflix、YouTube、爱奇艺 音乐：Pandora、网易云音乐、豆瓣FM 社交网络：Facebook、Twitter、LinkedIn、新浪微博 个性化阅读：Digg、Flipboard、今日头条 基于位置的服务：Foursquare 个性化广告：Facebook Audience Network 推荐系统实验方法在推荐系统中，主要有三种评测推荐效果的实验方法：离线实验、用户调查、在线实验。 推荐系统评测指标 用户满意度：用户的主观感受，主要通过用户调查的方式获得，也可以间接从用户行为统计中得到。 预测准确度：度量一个推荐系统或推荐算法预测用户行为的能力。评分预测的预测准确度一般通过计算测试集和训练集的均方根误差(RMSE)和平均绝对误差(MAE)得到。TopN推荐的预测准确度一般通过计算测试集和训练集的准确率(precison)和召回率(recall)得到。 令rui是用户u对物品i的实际评分，r^ui是推荐算法给出的预测评分，T是测试集，那么：RMSE = sqrt(Σu,i∈T(rui-r^ui)2 / |T|)MAE = Σu,i∈T|rui-r^ui| / |T| 令R(u)是用户u在训练集上的推荐结果，T(u)是用户u在测试集上的行为结果，U是用户集合，那么： Precision = Σu∈U|R(u) ∩ T(u)| / Σu∈U|R(u)| Recall = Σu∈U|R(u) ∩ T(u)| / Σu∈U|T(u)| 覆盖率：描述一个推荐系统对物品长尾的发掘能力。 假设用户集合为U，物品集合为I，推荐系统给每个用户推荐一个长度为N的物品列表R(u)，那么：Coverage = |∪u∈UR(u)| / |I| 多样性：为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域。 新颖性：是指给用户推荐那些他们以前没听说过的商品。 惊喜度(serendipity)：如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高。 信任度：提高信任度的方法是给出合理的推荐解释。 实时性：推荐系统需要实时地更新推荐列表来满足用户新的行为变化，并且需要能够将新加入系统的物品推荐给用户。 健壮性(robust)：衡量一个推荐系统抗击作弊的能力。 在众多指标中，作者认为：对于可以离线优化的指标，应该在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。 常见推荐系统算法推荐系统是联系用户和物品的媒介，而推荐联系用户和物品的方式主要有3种，如下图所示。 3种联系用户和物品的推荐系统 第一种方法，首先找到用户喜欢的物品，然后找到与这些物品相似的物品推荐给用户。基于这种方法可以给出如下的推荐解释：购买了该商品的用户也经常购买这些商品。这种方法通常被称为基于物品的协同过滤算法(item-based collaborative filtering)。第二种方法，首先找到和用户有相似兴趣的其他用户，然后推荐这些其他用户喜欢的物品。这种方法通常被称为基于用户的协同过滤算法(user-based collaborative filtering)。第三种方法，首先找到用户感兴趣的物品特征，然后推荐包含这些特征的物品。这种方法核心思想是通过隐含特征联系用户兴趣和物品，通常被称为隐语义模型算法(latent factor model)。 协同过滤算法个性化推荐系统的一个重要算法是基于用户行为分析，学术界一般将这种类型的算法称为协同过滤算法(collaborative filtering)。 顾名思义，协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤掉自己不感兴趣的物品，从而越来越满足自己的需求。 基于物品的协同过滤算法基于物品的协同过滤算法(以下简称ItemCF)，是目前业界应用最多的算法，最早由电子商务公司亚马逊提出。ItemCF算法给用户推荐那些和他们之前喜欢的物品相似的物品，它的主要步骤分为两步。 (1) 计算物品之间的相似度 (2) 根据物品的相似度和用户的历史行为给用户生成推荐列表 第一步计算相似度可用余弦相似度公式 令N(i)是喜欢物品i的用户集合，那么物品i和物品j的相似度可定义为： wij = |N(i) ∩ N(j)| / sqrt(|N(i)||N(j)|) 第二步计算用户对物品的兴趣，如下公式的含义是：和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。 令puj为用户u对物品j的兴趣，wji是物品j和物品i的相似度，rui是用户u对物品i的兴趣（对于隐反馈数据集，如果用户u对物品i有过行为，可简单令rui=1），S(j,K)是和物品j最相似的K个物品的集合，那么： puj = Σi∈N(u)∩S(j,K) wjirui 最后选取该用户兴趣值最高的N的物品作为推荐列表。 基于用户的协同过滤算法基于用户的协同过滤算法(以下简称UserCF)，是推荐系统中最古老的算法。UserCF算法先找到和他有相似兴趣的其他用户，然后把那些用户喜欢的、而他没有听说过的物品推荐给他，它的主要步骤分为两步。 (1) 找到和目标用户兴趣相似的用户集合 (2) 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户 第一步计算用户的兴趣相似度可用余弦相似度公式 令N(u)是用户u曾经有过正反馈的物品集合，那么用户u和用户v的相似度可定义为： wuv = |N(u) ∩ N(v)| / sqrt(|N(u)||N(v)|) 第二步计算用户对物品的兴趣 令pui为用户u对物品i的兴趣，wuv是用户u和用户v的相似度，rvi是用户v对物品i的兴趣（对于隐反馈数据集，如果用户v对物品i有过行为，可简单令rvi=1），S(u,K)是和用户u兴趣最相似的K个用户的集合，那么： pui = Σv∈N(i)∩S(u,K) wuvrvi 最后选取该用户兴趣值最高的N的物品作为推荐列表。 隐语义模型隐语义模型算法(以下简称LFM)，是最近几年推荐系统领域最为热门的研究话题。LFM算法的核心思想是通过隐含特征联系用户兴趣和物品，它的主要步骤分为三步。 (1) 对物品进行分类 (2) 确定用户对哪些类的物品感兴趣以及感兴趣的程度 (3) 对于给定的类，确定物品在这个类的权重，并且选择性地推荐给用户 关于如何给物品分类，一个简单方案是由编辑来手动分类，但这样存在很强的主观性和较大的工作量。为了解决这个困难，研究人员提出可以从用户数据出发，基于隐含语义分析技术(latent variable analysis)自动找到哪些类，然后进行个性化推荐。隐含语义分析技术有很多著名的模型和方法，比如pLSA、LDA、隐含类别模型、隐含主题模型、矩阵分解等。 LFM通过如下公式计算用户u对物品i的兴趣： Preferenceui = Σk∈[1,K] pu,kqi,k 其中pu,k度量了用户u的兴趣和第k个隐类的关系，而qi,k度量了第k个隐类和物品i的关系。这两个参数的计算需要一点最优化理论或者机器学习的知识，这里不多作介绍。 三种算法的优缺点比较 LFM是一种基于机器学习的算法，有较好的理论基础。ItemCF/UserCF是基于邻域的方法，更多的是一种基于统计的方法，没有学习过程。 假设有M个用户和N个物品，选取F个隐类。UserCF需要存储用户的相似度矩阵，存储空间是O(M*M)。ItemCF需要存储物品的相似度矩阵，存储空间是O(N*N)。LFM需要的存储空间是O(F*(M+N))。如果用户数很多，UserCF将会占据很大的内存。如果物品数很多，ItemCF将会占据很大的内存。LFM存储空间最少，这在M和N很大时可以很好地节省离线计算的内存。 假设有M个用户和N个物品和K条用户对物品的行为记录。那么，UserCF计算用户表的时间复杂度是O(N*(K/N)2)，而ItemCF计算物品表的时间复杂度是O(M*(K/M)2)。而对于LFM，如果用F个隐类，迭代S次，那么它的时间复杂度是O(K*F*S)。在一般情况下，LFM的时间复杂度要稍微高于UserCF和ItemCF，主要是因为该算法需要多次迭代。 ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果，但LFM无法提供这样的解释。 总结在互联网应用中可以看到大量推荐系统的应用，它主要解决了信息过载的问题，通过算法主动帮助用户找到自己感兴趣的内容。常见的推荐系统算法有三种，分别代表三种联系用户和物品的方式，它们是：基于物品的协同过滤算法(ItemCF)，基于用户的协同过滤算法(ItemCF)，隐语义模型算法(LFM)。三种方法各有优劣，需要根据实际场景选择合适的算法，通过不断优化指标找到最优算法。","tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"http://www.secondplayer.top/tags/推荐系统/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://www.secondplayer.top/tags/读书笔记/"}]},{"title":"使用redis的有序集合实现排行榜功能","date":"2017-07-23T05:43:36.000Z","path":"2017/07/23/redis-sorted-set/","text":"排行榜是业务开发中常见的一个场景，如何设计一个好的数据结构能够满足高效实时的查询，下面我们结合一个实际例子来讨论一下。 场景选手报名参加活动，观众可以对选手进行投票，每个观众对同一名选手只能投一票，活动期间最多投四票。后台需要提供如下接口： 接口1：返回TOP 10的选手信息及投票数 接口2：返回活动总参与选手数及总投票数 接口3：对于每个选手，返回自己的投票数，排名，距离上一名差的票数 基于数据库的方案首先需要一张表存储投票记录，一次投票就是一条记录。这张表相当于投票明细，判断每人只投一张票以及最多投四张表都依赖对这张表的查询。如果直接对这张表做TOP 10的查询，则需要根据选手id做聚合查询，这样每次查询必然耗时。为了优化查询，可以增加另一张排行榜表，用一个定时任务每隔一段时间对原表做聚合查询，然后将结果写进排行榜表里，表里包含投票数及排名的字段，这样查询TOP 10和排名的时候直接查这张表。引入另一张表加快了性能，但牺牲了实时性，活动说明里需加上类似“榜单数据每10分钟同步一次”的话来告知用户。 基于redis的方案对于排行榜的需求，redis有一个数据结构非常适合做这件事，那就是有序集合(sorted set)。 redis的有序集合相关命令有序集合和集合一样可以存储字符串，另外有序集合的成员可以关联一个分数(score)，这个分数用于集合排序。下面以投票为例说明常见的命令，vote_activity是有序集合的key。12345678910111213141516171819202122232425262728#给Alice投票redis&gt; zincrby vote_activity 1 Alice&quot;1&quot; #给Bob投票redis&gt; zincrby vote_activity 1 Bob&quot;1&quot;#给Alice投票redis&gt; zincrby vote_activity 1 Alice&quot;2&quot;#查看Alice投票数redis&gt; zscore vote_activity Alice&quot;2&quot;#获取Alice排名(从高到低，zero-based)redis&gt; zrevrank vote_activity Alice(integer) 0#获取前10名(从高到低)redis&gt; zrevrange vote_activity 0 91) &quot;Alice&quot;2) &quot;Bob&quot;#获取前10名及对应的分数(从高到低)redis&gt; zrevrange vote_activity 0 9 withscores1) &quot;Alice&quot;2) &quot;2&quot;3) &quot;Bob&quot;4) &quot;1&quot;#获取总参与选手数redis&gt; zcard vote_activity(integer) 2 接口实现回到最开始的场景，大部分需求都已经得到满足，还剩下两个数据需要单独说一下。接口2中的总投票数没有直接的接口获得，一种方法是先用ZRANGE遍历所有的key，然后对score进行求和，另一种方法是对总票数单独用一个数据结构存储。接口3的距离上一名差的票数，先用ZREVRANK获取自己排名，然后用ZREVRANGE获取上一排名的分数，最后用自己的分数减去上一名的分数即可，代码示例如下：12345678def get_next_step(redis_key, member): next_step = None score = redis.zscore(redis_key, member) rank = redis.zrevrank(redis_key, member) if rank &gt; 0: next_member = redis.zrevrange(redis_key, rank - 1, rank - 1, withscores=True) next_step = next_member[0][1] - score return next_step 另外如果两个key的score相同，排序逻辑是按照key的字母序排序。在有些情况下这个可能不满足实际要求，因此需要按实际情况重新设计key。比如如果要求同分数情况下按时间排序，那么key最好加上时间戳前缀。 redis与数据库的同步redis通常是作为缓存层加速查询的，如果数据没有做持久化则有概率会丢失数据。一个方案是用定时任务定时同步redis与数据库的数据，数据库里存储着原始数据，通过计算数据库的数据和redis做对比，可以修正由于redis不稳定导致的数据不一致。这里需要注意的是在同步过程时redis的数据有可能还在增长，因此最好先读redis的数据，然后记下时间，查询指定时间段里的数据库的数据，最后再用ZINCRBY增量修正redis数据，而不是直接用ZADD覆盖redis数据。 总结redis的有序集合是一个非常高效的数据结构，可以替代数据库里一些很难实现的操作。它的一个典型应用场景就是排行榜，通过ZRANK可以快速得到用户的排名，通过ZRANGE可以快速得到TOP N的用户列表，它们的复杂度都是O(log(N))，用来替代数据库查询可以大大提升性能。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.secondplayer.top/tags/Redis/"}]},{"title":"使用redis实现分布式锁","date":"2017-07-16T05:40:10.000Z","path":"2017/07/16/redis-distribution-lock/","text":"背景在类似秒杀这样的并发场景下，为了确保同一时刻只能允许一个用户访问资源，需要利用加锁的机制控制资源的访问权。如果服务只在单台机器上运行，可以简单地用一个内存变量进行控制。而在多台机器的系统上，则需要用分布式锁的机制进行并发控制。基于redis的一些特性，利用redis可以既方便又高效地模拟锁的实现。 一个简单方案让我们先从一个简单的实现说起，这里用到了redis的两个命令，SETNX和EXPIRE。如果lock_key不存在，那么就设置lock_key的值为1，并且设置过期时间；如果lock_key存在，说明已经有人在使用这把锁，访问失败。12345def acquire_lock(lock_key, expire_timeout=60): if redis.setnx(lock_key, 1): redis.expire(lock_key, expire_timeout) return True return False 逻辑上看似乎没有问题，但是考虑一下异常情况：如果setnx设置成功，但expire由于某些原因（比如超时）操作失败，那么这把锁就永远存在了，也就是所谓的死锁，后面的人永远无法访问这个资源。 利用时间戳取值的方案为了解决死锁，我们可以利用setnx的value来做文章。上例中的我们设的value是1，其实并没有派上用场。因此可以考虑将value设为当前时间加上expire_timeout，当setnx设置失败后，我们去读lock_key的value，并且和当前时间作比对，如果当前时间大于value，那么资源理当被释放。代码示例如下：123456789def acquire_lock(lock_key, expire_timeout=60): expire_time = int(time.time()) + expire_timeout if redis.setnx(lock_key, expire_time): redis.expire(lock_key, expire_timeout) return True redis_value = redis.get(lock_key) if redis_value and int(time.time()) &gt; int(redis_value): redis.delete(lock_key) return False 然而仔细推敲下这段代码仍然能发现一些问题。第一，这个方案依赖时间，如果在分布式系统中的时间没有同步，则会对方案产生一定偏差。第二，假设C1和C2都没拿到锁，它们都去读value并对比时间，在竞态条件(race condition)下可能产生如下的时序：C1删除lock_key，C1获得锁，C2删除lock_key，C2获得锁。这样C1和C2同时拿到了锁，显然是不对的。 改进后的方案幸运的是，redis里还有一个指令可以帮助我们解决这个问题。GETSET指令在set新值的同时会返回老的值，这样的话我们可以检查返回的值，如果该值和之前读出来的值相同，那么这次操作有效，反之则无效。代码示例如下：123456789101112def acquire_lock(lock_key, expire_timeout=60): expire_time = int(time.time()) + expire_timeout if redis.setnx(lock_key, expire_time): redis.expire(lock_key, expire_timeout) return True redis_value = redis.get(lock_key) if redis_value and int(time.time()) &gt; int(redis_value): expire_time = int(time.time()) + expire_timeout old_value = redis.getset(lock_key, expire_time) if int(old_value) == int(redis_value): return True return False 这个方案基本可以满足要求，除了有一个小瑕疵，由于getset会去修改value，在竞态条件下可能会被修改多次导致timeout有细微的误差，但这个对结果影响不大。 最终方案以上方案实现起来略显繁琐，但从redis 2.6.12版本开始有一个更为简便的方法。我们可以使用SET指令的扩展 SET key value [EX seconds] [PX milliseconds] [NX|XX] ，这个指令相当于对SETNX和EXPIRES进行了合并，因而我们的算法可以简化为如下一行：123def acquire_lock(lock_key, expire_timeout=60): ret = redis.set(lock_key, int(time.time()), nx=True, ex=expire_timeout): return ret 总结在redis 2.6.12版本之后我们可以用一个简单的SET命令实现分布式锁，而在此版本之前则需要将SETNX和GETSET配合使用一个较为繁琐的方案。简化后的方案对于开发者来说当然是好事，但通过学习这一演变过程我们会对问题有更深刻的印象。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.secondplayer.top/tags/Redis/"}]},{"title":"使用Hexo搭建个人静态博客","date":"2016-06-12T06:42:23.000Z","path":"2016/06/12/hexo-blog-setup/","text":"最近有时间折腾了一下建一个个人博客，在对比了几家之后，最终决定用Hexo作为框架，GitHub作为部署平台搭建博客。VPS选用的是AWS，新用户可以免费使用1年的EC2，足够用来体验了。 申请VPSVPS指的是虚拟服务器，国内推荐用阿里云，国外推荐用Linode, Digital Ocean, AWS。我选择的是AWS，主要有几个原因，一是因为新用户可以试用免费1年，二是因为公司用的就是AWS，对其各项操作比较熟悉，最后一个原因是选择一个国外服务器可以自己搭建ShadowSocks科学上网。 申请域名域名申请服务商，国内有万网，美橙，国外有GoDaddy, NameCheap。我选择的是NameCheap，主要因为价格因素。你要问国内的那些更便宜为啥不选？呵呵国内的情况你懂的。 DNS解析DNS解析推荐DNSPOD，业界良心，服务免费且强大。域名绑定前记得先到NameCheap控制台设置DNS解析到DNSPOD提供的两个免费DNS解析服务器，具体参考这里。 Hexo安装及配置前面把主机和域名搞定了，现在开始在主机上搭建博客了。提到博客，一般都会选用经典的WordPress搭建。不过现在越来越多的个人博客都采用静态博客框架，典型的如Hexo， Jekyll， Octopress。从流行度和技术栈的角度来看，我倾向于选择Hexo。Hexo是一个用Node.js搭建的博客框架，简单强大易上手。静态文件用Markdown编写，Hexo会根据静态文件自动生成网页。 安装依赖环境 安装Git 1$ sudo apt-get install git 安装Node.js 通常用nvm(Node.js Version Manager)安装Node环境安装必要环境1$ sudo apt-get install build-essential libssl-dev 下载nvm1$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh 查看可用版本1$ nvm ls-remote 选取最新版本，这里我们安装v4.4.5，并将其设为默认123$ nvm install 4.4.5$ nvm alias default 4.4.5$ nvm use default 安装Hexo 我们通过npm分别安装hexo客户端和服务端 12$ npm install -g hexo-cli$ npm install -g hexo-server 生成文章 初始化hexo环境 我们把hexo_blog作为博客目录名，首先初始化hexo 123$ hexo init ~/hexo_blog$ cd ~/hexo_blog$ npm install 修改配置文件_config.yml 配置Site, URL, Directory, Writing等基本信息，详细参考这篇配置文档这里建议设置default_layout为draft，这样默认生成文章在Draft里，确认后再发布到Public。 发布文章 新建文章，以名称first_post为例 1$ hexo new first-post 编辑文章，文章都存放在source目录下 1$ vim ~/hexo_blog/source/_drafts/first-post.md 发布文章，这将会把文章从draft移到post目录 1$ hexo publish first-post 运行服务 启动服务器，默认起在4000端口，成功后访问http://localhost:4000 预览效果 1$ hexo server 部署博客我们需要选择一个静态文件的托管平台，首选GitHub，国内可以考虑Coding（最近收购了GitCafe）。 创建GitHub Repository 参考这个步骤，创建一个名为hexo_static的repo，注意设置为Public 修改配置文件_config.yml，注意替换$username 1234deploy: type: git repo: https://github.com/$username/hexo_static.git branch: master 安装hexo git插件 1$ npm install hexo-deployer-git --save 部署 12$ hexo generate$ hexo deploy 按照提示输入用户名和密码，一切步骤完成后，所有文件都已生成并提交到Git上了 自动化整个自动化的思路是：运行该脚本，生成博客静态文件，通过hexo deploy实现自动提交到Git，然后通过本地更新代码，对关联的空分支进行git push操作，触发post-receive钩子，从而将静态文件同步到/var/www/hexo目录，而该目录正是Nginx将80端口转发到本地的路径。 初始化空仓库 1$ git init --bare ~/hexo_bare 创建git hooks 1$ vim ~/hexo_bare/hooks/post-receive 这里我们用到了post-receive这个钩子，当一个本地仓库执行git push后会触发。post-receive具体内容为 123#!/bin/bashgit --work-tree=/var/www/hexo --git-dir=/home/$USER/hexo_bare checkout -f 将空仓库关联到主仓库 123$ git clone https://github.com/$username/hexo_static.git ~/hexo_static $ cd ~/hexo_static$ git remote add live ~/hexo_bare 创建自动化脚本 1$ vim ~/hexo_blog/hexo_git_deploy.sh 脚本内容为 1234567#!/bin/bashhexo cleanhexo generate hexo deploy( cd ~/hexo_static ; git pull ; git push live master) Nginx配置 创建/var/www/hexo目录，稍后会将Nginx的请求映射到该目录 123$ sudo mkdir -p /var/www/hexo$ sudo chown -R $USER:$USER /var/www/hexo$ sudo chmod -R 755 /var/www/hexo 编辑/etc/nginx/sites-available/default1$ sudo vim /etc/nginx/sites-available/default 配置Nginx将80端口的请求映射到/var/www/hexo目录下123456server &#123; listen 80 default_server; listen [::]:80 default_server ipv6only=on; root /var/www/hexo; index index.html index.htm;... 重启Nginx 1$ sudo service nginx restart 发布流程至此，我们可以总结下今后发布文章或更新博客的流程 1234$ hexo new my-post$ vim ~/hexo_blog/source/_draft/my-post.md$ hexo publish my-post$ hexo generate 接着运行hexo server，然后在http://localhost:4000 上预览效果，如果不满意则继续修改my-post.md（此时在_post目录下），重新生成文件（hexo generate），再预览直到可以发布为止 而最终对外发布，我们只需要敲下一行命令就完成了 1$ ~/hexo_blog/hexo_git_deploy.sh 其他 主题 默认hexo的主题是landscape，如果你想与众不同的话，可以用下别的主题或者自定义主题。官方收录的请点击这里，我选择的是indigo，主要看中的是他的Material Design风格 评论 常见的评论系统有Disqus，多说，友言等，我选择的是多说。接入非常简单，去网站上注册个账号，然后将示例代码插到网页中即可 统计 流量统计选择cnzz(现已被整合进Umeng+) 监控 可以接入监控宝 参考 Hexo Documentation How to Create a Blog with Hexo On Ubuntu 14.04","tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.secondplayer.top/tags/Hexo/"}]},{"title":"Hello World","date":"2016-06-10T16:00:00.000Z","path":"2016/06/11/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]