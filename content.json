[{"title":"机器学习笔记12: 因子分析","date":"2018-07-15T13:38:47.000Z","path":"2018/07/15/machine-learning-factor-analysis/","text":"上一节我们介绍了用EM算法求解混合高斯模型，但这个算法通常是在样本数足够多的情况下才成立，即满足样本数m远远大于特征数n。 如果n &gt;&gt; m，那么在模型计算参数的时候会遇到一些问题。计算均值和协方差函数这两个参数的公式为： 当n &gt;&gt; m时，我们会发现Σ是奇异矩阵，这也就意味着Σ-1不存在，并且1/|Σ|1/2 = 1/0，这几项在估计多元高斯分布的密度函数中都会用到，因此我们没法进行拟合。 更一般的，如果m没有在一定范围内大于n，那么用极大似然估计法估计参数的效果都很差。然而我们还是希望用多元高斯分布来估计样本，应该怎么办呢？ 限制协方差矩阵如果我们没有足够的数据来估计协方差矩阵Σ，那么可以考虑给Σ做一些假设。比如我们可以假设Σ是对角矩阵，那么可以计算出： 回顾一下之前我们说过高斯密度函数的等高线是椭圆，如果Σ是对角矩阵，那么就意味着椭圆的主轴与坐标轴是平行的。 有时我们会对Σ做更强的假设，Σ不仅是对角矩阵，而且对角上每个元素的值都是相等的，我们可以写成：Σ = σ2I，其中 σ2是我们可以控制的参数，通过极大似然估计可以计算出： 这个模型对应的等高线是个圆形(在二维空间是圆，在三维空间是球)。 如果我们要估计出完整的Σ，需要满足m ≥ n + 1才能保证Σ是非奇异矩阵。而如果使用上面两种假设，只需要满足m ≥ 2 就能保证Σ是非奇异矩阵。 但是使用上面两种假设也是有明显缺点的，我们假设了特征之间是独立不相关的，这个假设太强了，我们还是希望能捕捉到特征之间的关系的。接下来我们介绍一种因子分析的模型，它使用了比对角矩阵更多的特征，同时保留了特征之间的关系，并且不需要计算一个完整的Σ。 边缘与条件高斯分布在引入因子分析模型之前，我们先介绍下如何在多元高斯分布下求解边缘与条件高斯分布。 假设我们有如下的随机变量： 其中x1 ∈ Rr，x2 ∈ Rs，x ∈ Rr + s。假设x服从高斯分布N(μ, Σ)，其中 上式中的μ1 ∈ Rr，μ2 ∈ Rs，Σ11 ∈ Rr x r，Σ12 ∈ Rr x s，以此类推。注意由于协方差矩阵的对称性，Σ12 = Σ21T。 在我们的假设中，x1和x2的联合分布是多元高斯分布，那么x1的边缘分布是什么呢？不难证明，E[x1] = μ1，Cov(x1) = E[(x1 - μ1)(x1 - μ1)T] = Σ11。关于Cov(x1)的证明如下： 比对矩阵左上角部分就可得到结论。由此可见，多元高斯分布的边缘分布仍然是多元高斯分布，即x1 ~ N(μ1, Σ11)。 接下来我们看条件分布应该如何求解。根据多元高斯分布的定义，可得x1 | x2 ~ N(μ1|2, Σ1|2)，其中： 在接下来的因子分析模型推导中，上面这些公式会非常有用。 因子分析模型在因子分析(factor analysis)模型中，我们给出(x, z)的联合分布如下： 其中z ∈ Rk是隐含随机变量，μ ∈ Rn，变换矩阵Λ ∈ Rn x k，对角矩阵Ψ ∈ Rn x n，k通常选择为比n小的一个数。 上述过程可以理解为：首先在k维空间中按照多元高斯分布生成z(i)，然后通过μ + Λz(i)将z(i)映射到n维空间中，最后由于x(i)与上述模型之间存在误差，所以在模型基础上增加协方差矩阵Ψ的噪音，从而得到训练数据x(i)。 上述过程可以等价表示为： 其中ε和z是独立的 上述过程可以进一步表述为：高维样本点是通过低维样本点经过高斯分布、线性变换、误差扰动生成的，因此高维数据可以用低维数据来表示。 下面我们开始计算模型参数。由于x和z的联合分布符合多元高斯分布，所以可以表示为： 我们需要计算出μzx和Σ。首先由于z ~ N(0, I)，所以E[z] = 0，因此有： 将两个结果结合起来，就有： 然后我们来计算Σ。我们很容易证明Σzz = Cov(z) = I。另外，我们也可以推导出Σzx： 同样我们也可以推导出Σxx： 综合上述结果，我们可以得到： 由此，我们也能得到x的边缘分布是x ~ N(μ, ΛΛT + Ψ)。因此对于样本{x(i); i=1, …, m}，我们对其进行极大似然估计： 但是我们没有办法通过求导的方式获得各个参数，根据上一节的经验，我们需要借助EM算法进行求解。 因子分析的EM算法E步的推导比较简单。我们需要计算Qi(z(i)) = p(z(i)|x(i); μ, Λ, Ψ)。根据之前条件分布的讨论，z(i)|x(i); μ, Λ, Ψ ~ N(μz(i)|x(i), Σz(i)|x(i))，其中： 将其代入到Qi(z(i))中，可得： 接下来我们来看M步，我们需要最大化的目标函数是： 我们需要分别求出μ, Λ, Ψ。这三个参数的推导需要有一定数学技巧，这里就省略推导步骤，直接给出结果了。感兴趣的读者可以查阅讲义部分对Λ的推导。 其中Ψ是对角矩阵，只需将Φ上对角线上的元素放在Ψ对应位置上就得到了Ψ。 总结 当样本数m远远小于特征数n时，用EM算法求解混合高斯模型是不可行的，我们需要使用因子分析模型 因子分析模型的方法本质是：高维样本点是通过低维样本点经过高斯分布、线性变换、误差扰动生成的，因此高维数据可以用低维数据来表示 参考资料 斯坦福大学机器学习课CS229讲义 Factor Analysis 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记11: K-Means算法和EM算法","date":"2018-07-01T13:03:44.000Z","path":"2018/07/01/machine-learning-k-means-and-em-algorithm/","text":"这一节开始我们讨论非监督学习(Unsupervised Learning)的算法。在监督学习算法中，训练数据既包含特征也包含标签，通常表示为{(x(1), y(1)), …, (x(m), y(m))}；而在非监督学习中，训练数据只有特征没有标签，通常表示为{x(1), …, x(m)}。 K-Means算法聚类(clustering)问题是最常见的非监督学习问题。对于一组无标签数组，可以用聚类算法将数据分成若干相似的“群组”，从而发掘数据中的隐藏结构。 K-Means算法是最常见的一种聚类算法，算法步骤描述如下： 随机选择k个中心点(centroids): μ1, μ2, …, μk 重复如下过程直到收敛：{ 对于每个样本i，令： 对于每个中心点j，令： } 在上面的算法中，k表示我们想要聚类的个数，μj表示目前我们对中心点的猜测。算法的第一步是初始化中心点，这个可以通过随机选择k个样本数据获得。算法的第二步是不断循环如下两个过程：首先将样本x(i)“指派”给离它距离最近的中心点μj，然后将中心点μj更新为所有被“指派”给它的样本距离的平均值。下图展示了算法的执行过程： 图(a)表示原始的训练数据。图(b)表示随机选取了两个初始中心点，用记号x表示。图(c)表示将每个训练数据指派给离它最近的中心点，图中用不同颜色表示数据与中心点的关系。图(d)表示更新中心点的位置。图(e)和(f)表示又进行了一轮迭代。 K-Means算法一定可以保证收敛。特别的，我们定义失真函数(distortion function)： 因此，J函数表示每个样本点离它对应中心点的平方和。可以证明，K-Means算法其实就是对J函数应用坐标下降算法。具体来说，K-Means算法内层循环的第一步是固定μ使c关于J求最小化，第二步是固定c使μ关于J求最小化。因此J是单调递减的，J的值必然是收敛的。 由于J函数不是凸函数，所以坐标下降法未必能得到全局最优解，也就是说K-Means算法可能会得到局部最优解。为了防止K-Means算法得出的结果是局部最优解，通常可以用不同的初始值多运行几次算法，然后取使得J函数最小的那个参数值。 混合高斯模型这一部分我们介绍使用混合高斯模型进行聚类的算法。回顾在高斯判别分析(GDA)模型中，我们假设x是连续的随机变量，p(y)服从伯努利分布，p(x|y)服从多元正态分布，通过极大似然法使得联合概率p(x, y)最大，从而求解出模型的参数。 而在非监督学习的设定下，我们没有y的数据，因此我们引入一个隐含(latent)随机变量z。我们建立联合分布p(x(i), z(i)) = p(x(i)|z(i))p(z(i))，其中p(z(i))服从参数为φ的多项式分布(p(z(i) = j) = φj)，p(x(i)|z(i))服从正态分布N(μj, Σj)。我们的模型首先让z(i)随机地从1到k中取值，然后x(i)是从k个高斯分布中选择第z(i)个分布，这样的模型就称之为混合高斯模型(Mixtures of Gaussians)。由于z(i)是不可观察的隐含变量，这使得我们的计算变得更为困难。 为了计算模型中φ, μ和Σ的值，我们写出似然函数： 如果我们通过用求导的方式来求解参数，我们会发现这是不可能做到的。 由于z(i)是用来表示x(i)是来自k个高斯分布中的哪一个的，如果我们知道z(i)的取值的话，那么问题就变得简单了，我们将问题简化为： 对此似然函数最大化，我们求得各参数为： 因此，如果z(i)是已知的，那么最大化似然函数的问题就很简单了，而且求解参数的结果和通过GDA求解得到的参数非常相似。 但是在我们实际问题中，z(i)是未知的，那我们应该怎么办呢？ 我们可以采用EM算法。EM算法是一个迭代式的算法，它总共分为两步。在这个问题中，E步尝试猜测一个合理的z(i)值，M步按照上一步猜测的z(i)来更新模型的参数。在M步，由于我们假设E步猜测的z(i)是正确的，因此最大化似然函数的问题变得简单了。算法步骤描述如下： 重复如下过程直到收敛：{E步：对于每个i, j，我们令： M步：按如下公式更新参数： } 在E步中，我们计算的是在给定x(i)和其他参数情况下z(i)的后验概率，根据贝叶斯公式，我们有： 上式中的p(x(i)|z(i) = j; μ,Σ)是通过平均值为μj，协方差为Σj的高斯分布在x(i)上的概率密度计算得出；p(z(i) = j;φ)的值由φ(j)计算得出。我们在E步中计算的wj(i)可以认为是对z(i)的软猜测(软猜测是指猜测的结果是[0,1]之间的概率值，硬猜测是指0或1的取值)。 EM算法和K-Means算法的迭代步骤其实比较类似，不同的是K-Means算法中每次对c(i)的更新是硬猜测，而EM中每次对w(i)的更新是软猜测。和K-Means算法相同的是，EM算法也可能得到局部最优解，所以用不同的初始参数迭代会得到更好的结果。 这一部分我们用EM算法的思想讲了混合高斯模型问题，后面我们会讲更通用的EM算法，以及EM算法是如何保证算法的收敛性的。在讲解通用EM算法之前，我们先要介绍一个定理作为预备知识。 Jensen不等式令f是一个定义域为实数的函数。若f是凸函数(convex function)，则f’’(x) &gt;= 0。如果f的定义域是向量，那么凸函数的条件变为f的Hessian矩阵H是半正定矩阵(H &gt;= 0)。如果对于所有的x都有f’’(x) &gt; 0，那么我们说f是严格凸函数。对于定义域是向量的情况，如果H是正定矩阵(H &gt; 0)，那么我们说f是严格凸函数。 Jensen不等式(Jensen’s inequality)可表述如下： 令f是凸函数，X是随机变量，那么有：E[f(X)] &gt;= f(EX)。如果f是严格凸函数，那么E[f(X)] = f(EX)当且仅当X = E[X]的概率为1(即X是常量)。 由于我们在书写期望的时候有时候会把括号省略掉，所以上式中的EX是E[X]的缩写。为了对这个公式有直观的理解，我们可以用下图来解释： 上图中的曲线表示函数f，X是一个随机变量，它有一半的概率取a，有一半的概率取b，所以E[X]介于a和b的中间。另一方面我们可以看到y轴上f(a)，f(b)和f(EX)的值，而E[f(X)]介于f(a)和f(b)的中间。由于凸函数的特性，很容易看出一定有E[f(X)] &gt;= f(EX)。 事实上很多人会记不清这个不等式的方向，有了上面这个图的话可以帮助我们更好的记忆。 注意，如果f是凹函数(concave function)(即f’’(x) &lt;= 0或H &lt;= 0)，Jensen不等式也是成立的，只不过不等式的方向变了，即E[f(X)] &lt;= f(EX)。 EM算法这一节我们介绍通用的EM算法。假设我们的训练集是m个互相独立的样本{x(1), …, x(m)}，我们希望对p(x, z)进行建模，其似然函数为： 直接通过最大化似然函数求解参数是比较困难的。这里z(i)是隐含的随机变量，如果z(i)的值是已知的，那么问题将变得简单。 在这种情况下，EM算法给出了一个高效地求解最大化似然函数的方法。直接最大化l(θ)可能比较困难，那么我们的策略是不断地构造l的下界(E步)，然后最大化该下界(M步)。 对于每一个i，令Qi是z(i)的某个分布(ΣzQi(z) = 1, Qi(z) &gt;= 0; 如果z(i)是连续的，那么Qi是概率密度函数)，引入Qi后，我们有： 上式中最后一步的不等式是由于Jensen不等式推导而来。具体来说由于f(x) = log(x)是凹函数，并且我们把 这一项看成是[p(x(i), z(i); θ)/Qi(z(i))]关于z(i)的期望，所以根据Jensen不等式： 其中“z(i) ~ Qi”的下标表示这是关于z(i)的期望，而z(i)满足Qi的分布。综上我们可以从等式(2)推导出等式(3)。 现在对于任意分布Qi，等式(3)给出了l(θ)的下界。Qi可以有很多选择，而我们应该选择Qi使得l(θ)最接近下界，也就是说我们希望选择Qi使得Jensen不等式的等号成立。 回顾下使得Jensen不等式等号成立的条件，对照上式可得如下的随机变量应该是常数： 其中c代表某个与z(i)无关的常数，我们把它写成如下的形式： 再加上我们已知ΣzQi(z(i)) = 1，因此可推导出： 所以Qi是在给定x(i)和θ两个参数下的z(i)的后验概率。 现在我们可以给出EM算法的基本步骤： 重复如下过程直到收敛：{E步：对于每个i，令： M步：按如下公式更新参数： } 算法中的E步给出了l(θ)的下界函数，M步是在最大化该下界。当算法收敛时我们便得到了最优解。那么这个算法为什么能收敛呢？这里我们简单证明一下。 假设θ(t)和θ(t+1)是EM算法连续两次迭代中的参数，而θ(t)是满足Jensen不等式成立的参数，所以： 而θ(t+1)是使得l(θ(t))最大化的参数，所以有： 因此我们证明了l(θ(t+1)) &gt;= l(θ(t))，所以EM算法是单调递增的，由此可证算法是收敛的。 另外，如果我们定义： 那么EM算法可以视为将J函数作坐标上升的过程，其中在E步是固定θ使Q关于J求最大化，M步是固定Q使θ关于J求最大化。 混合高斯模型重述在给出了通用的EM算法定义后，我们重新推导一下混合高斯模型中的EM算法。前面我们只描述了算法，但没有证明为什么参数需要按照给定的公式更新。 证明E步是很简单的，根据EM算法中的推导，可得： 而在M步中，我们需要最大化的目标函数是： 首先固定其他参数，关于μ作目标函数最大化，我们先求出目标函数关于μ的导数： 将导数设为0，可得： 这和我们之前给出的结论一致。 接下来我们再来求参数φ。将和φ有关的项进行合并，我们需要最大化的目标函数是： 除此之外，我们还有一个约束：所有的φj之和为1。为了最优化该问题，我们构建拉格朗日算子： 其中β是拉格朗日乘数，对L求导可得： 将导数设为0，可得： 另外我们求解β，可得： 将β代入回φj式中： 因此，我们推导出了参数φ。参数Σ的推导类似，这里就不做证明了。 总结 聚类算法是最常见的无监督学习算法，而K-Means算法是最常见的聚类算法 Jensen不等式：令f是凸函数，X是随机变量，那么有：E[f(X)] &gt;= f(EX)。如果f是严格凸函数，那么E[f(X)] = f(EX)当且仅当X = E[X]的概率为1(即X是常量)；如果f是凹函数，那么Jensen不等式也成立，但不等式的方向相反 EM算法是一个迭代式的算法，分为两个步骤：E步和M步；EM算法也可以视为将目标函数作坐标上升的过程，每个步骤都是固定一个参数并估计另一个参数 EM算法和K-Means算法的迭代过程比较类似，不同的是K-Means算法中每次对参数的更新是硬猜测，而EM中每次对参数的更新是软猜测；相同的是，两个算法都可能得到局部最优解，采用不同的初始参数迭代会有利于得到全局最优解 混合高斯模型是对单一高斯模型的扩展，可以通过EM算法进行参数求解 参考资料 斯坦福大学机器学习课CS229讲义 The K-Means Algorithm | Mixture of Gaussians | The EM Algorithm 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记10: 应用机器学习的建议","date":"2018-06-18T13:01:08.000Z","path":"2018/06/18/machine-learning-advice/","text":"这一节我们主要讨论机器学习具体应用中的一些建议，大部分内容都不会涉及到数学，但却可能是最难理解的一部分。另外本文的部分内容可能有一些争议，部分内容也不适用于学术研究。 机器学习算法的诊断我们来思考如下这个问题：在垃圾邮件分类问题中，我们从50000+的词汇表中选择了100个单词作为特征，然后选择贝叶斯逻辑回归(Bayesian logistic regression)模型，利用梯度下降法进行训练，但是训练得到的结果有20%的误差，这显然是不能接受的。 这个模型的目标函数如下： 那么我们下一步应该如何优化呢？通常我们可以有如下多个改进方式： 增加训练数据 尝试更小的特征集合 尝试更大的特征集合 尝试改变特征(比如使用邮件的标题和正文部分) 增加梯度下降的迭代次数 尝试用牛顿方法 改变正则化参数λ 尝试其他模型，比如SVM 这些方法都可能有用，但是挨个进行实验非常耗时，如果碰巧解决问题也可能只是运气好。因此更好的方法是我们对算法进行诊断，并根据诊断结果进行针对性的改进。 第一个的诊断方法是判断算法是过拟合还是欠拟合。过拟合意味着高方差，欠拟合意味着高偏差。我们可以通过学习曲线(learning curve)来诊断模型到底是高方差还是高偏差的。 下图展示的是高偏差模型的学习曲线： 可以看出，当训练集个数增加时，测试误差逐步减少，但是测试误差和训练误差之间仍存在较大的间隔。因此增加训练数据可以改善模型。 下图展示的是高方差模型的学习曲线： 可以看出，测试误差和训练误差之间的间隔很小，但是它们的误差率与理想值相差很远。 第二个诊断方法是关于优化算法和优化目标。这里我们继续接着刚才的例子讨论：假设通过BLR(贝叶斯逻辑回归)算法在垃圾邮件上的误差是2%，在正常邮件上的误差也是2%(对于正常邮件来说，这个误差是不可接受的)，而通过SVM算法在垃圾邮件上的误差是10%，在正常邮件上的误差是0.01%(对于正常邮件来说，这个误差是可以接受的)，但是我们倾向于使用BLR算法，因为BLR的计算效率更高。我们接下来应该怎么办？ 令SVM的参数为θSVM，BLR的参数为θBLR。其实我们真正在乎的是加权准确率(weighted accuracy)： 在上面的例子中，我们有：a(θSVM) &gt; a(θBLR) BLR的优化目标J(θ)是： 所以我们接下来诊断的方法就是比较J(θSVM)和J(θBLR)的大小。 第一种情况：a(θSVM) &gt; a(θBLR)，J(θSVM) &gt; J(θBLR)。BLR的目标是最大化J(θ)，但是现在BLR没能做到这点，因此问题在于优化算法，有可能算法还没有达到收敛。 第二种情况：a(θSVM) &gt; a(θBLR)，J(θSVM) &lt;= J(θBLR)。BLR确实做到了最大化J(θ)，但是BLR的加权准确率不如SVM，因此问题在于优化目标，J(θ)并不能很好地代表a(θ)。 因此回过头来看之前列的改进方式，每个改进方式其实都是在优化某一方面，具体描述如下： 增加训练数据：解决高方差 尝试更小的特征集合：解决高方差 尝试更大的特征集合：解决高偏差 尝试改变特征(比如使用邮件的标题和正文部分)：解决高偏差 增加梯度下降的迭代次数：解决优化算法问题 尝试用牛顿方法：解决优化算法问题 改变正则化参数λ：解决优化目标问题 尝试其他模型，比如SVM：解决优化目标问题 通过对算法进行诊断，我们可以有针对性地提出解决方案，从而避免无意义地进行错误的尝试。 误差分析和销蚀分析很多机器学习应用中会包含多个组成部分，各个部分之间形成一个整体的“管道(pipeline)”。比如下图展示了一个从图像中进行面部识别的管道图： 那么我们如何知道究竟哪个组件(component)对整体的贡献率最大呢？ 我们可以使用两种方法来分析这个问题。第一个方法是误差分析(error analysis)，误差分析是指从最基础的模型开始，依次增加一个组件，看每个组件对准确率的提升情况。比如对这个例子来说，我们可以分析如下： 组件 准确率 整体系统 85% 预处理(去除背景) 85.1% 面部识别 91% 分割眼睛 95% 分割鼻子 96% 分割嘴巴 97% 逻辑回归 100% 由此可见，面部识别和分割眼睛这两个组件对整体的贡献率较大。 第二个方法是销蚀分析(ablative analysis)。销蚀分析的步骤刚好相反，每次从完整系统中去除一个组件，看每个组件对准确率的降低情况。比如在一个垃圾邮件分类系统里，我们可以做如下分析： 组件 准确率 整体系统 99.9% 拼写检查 99.0% 发送方主机特征 98.9% 邮件头部特征 98.9% 邮件文本解析器特征 95% Javascript解析器 94.5% 图像特征 94% 由此可见，邮件文本解析器特征极大地提升了准确率，而邮件头部特征则对准确率几乎没有什么帮助。 如何上手一个机器学习问题通常我们面对一个机器学习问题，可以有如下两种思路： 思路1：仔细设计(Careful design) 花较长的时间设计出最好的特征，收集到最好的数据，建造出最好的算法架构 实现这个算法并希望它可以成功 优点：可能找到更新，更优雅的学习算法；适合用于学术研究 思路2：快速迭代(Build-and-fix) 先快速做一个可用版本 对算法进行误差分析和诊断，找到优化的方向并进行优化 优点：可以更快地将算法应用到实际场景中 另外还有一个建议：在项目的早期阶段，我们通常并不清楚系统每个部分的实现难度，因此我们需要避免进行过早优化(premature optimization)。 总结 通过对算法进行诊断，可以帮助我们确定优化方向，从而避免无意义地进行错误的尝试 误差分析和销蚀分析可以帮助我们确定一个系统中哪个组件的贡献率最大 应用机器学习的两种方法：仔细设计和快速迭代；仔细设计适合用于学术研究，但是要避免过早优化的风险 参考资料 斯坦福大学机器学习课CS229讲义 pdf 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记9: 模型选择","date":"2018-06-03T14:00:39.000Z","path":"2018/06/03/machine-learning-model-selection/","text":"假设我们为了某个学习问题需要从若干模型中选出最优模型，比如在多项式回归模型hθ(x) = g(θ0+θ1x+…+θkxk)中，我们应该如何选择合适的k值使得模型的偏差方差达成平衡？又比如在局部加权线性回归问题中，我们应该如何选择合适的波长参数τ使得模型的拟合效果最好呢？ 将上述问题给出形式化定义：假设我们有一个有限的模型集合M = {M1, …, Md}，我们应该选择哪个模型Mi作为最优模型呢？ 交叉验证假设训练集用S表示，考虑到上一讲的经验风险最小化(ERM)，我们可能会得出这样的一种算法： 使用S训练每一个Mi，获得对应的假设函数hi 选择训练误差最小的假设函数 很遗憾，这个算法是不可行的。比如在多项式回归问题中，使用越高阶的多项式，拟合的效果越好，因而训练误差越小。但是在上一讲中我们也说明过这样的选择会有很大的方差，实际上是一种过拟合。 下面我们对这个算法进行改进，这个算法叫做简单交叉验证(hold-out cross validation)。该算法描述如下： 将训练集随机分为两部分，比如选择70%的数据作为Strain，剩下的30%数据作为Scv 使用Strain训练每一个Mi，获得对应的假设函数hi 在Scv上测试每一个hi，计算相应的训练误差εˆScv(hi)，并选择训练误差最小的假设函数 由于我们是在Strain上训练的模型，并且在Scv上计算的训练误差，我们计算出的训练误差更接近于实际的泛化误差。通常用于测试的数据集Scv需要占到整个数据集的1/4到1/3之间，30%是典型值。 上述算法的第三步可以做一个改进，在选出最佳模型Mi后，再在全部数据集上做一次训练。通常这样做是很有效的，因为训练数据越多，模型参数越准确。 简单交叉验证算法的缺点是它“浪费”了30%的训练数据，尤其当训练数据本身就很稀少的情况下，去除了30%后剩下的就更少了。 下面的算法优化了数据的利用率，这个算法叫做k重交叉验证(k-fold cross validation)。该算法描述如下： 将训练集随机分为k个不相交的子集，记为S1, …, Sk 对每一个Mi，对每一个j=1, …, k，使用集合S1, …, Sj-1, Sj+1, …, Sk（也就是从训练集中去除Sj）进行训练，获得对应的假设函数hij，并在Sj上测试每一个hij，计算相应的训练误差εˆSj(hij)，并选择训练误差最小的假设函数Mi的近似泛化误差取所有εˆSj(hij)的平均值 选择近似泛化误差最小的模型Mi，然后使用全部训练集S再做一次训练，获得对应的假设函数hi 上述算法通常取k = 10。当训练数据非常稀少时，我们可以选取k = m，这意味着每次只留下一份数据用于测试，用尽可能多的数据用于训练，这种方法也被称为留一交叉验证(leave-one-out cross validation)。上面两种算法有效地利用了数据集，但缺点是增加了更多计算的次数。 上面我们介绍了很多交叉验证的算法用于在多个模型中选择一个最佳模型，实际上也可以用于对单个模型进行评估。比如你发明了一个新的学习算法，可以通过交叉验证计算测试集的训练误差是否合理来评估算法预测的质量。 特征选择模型选择的一个特殊并且重要的场景是特征选择(feature selection)。假设一个监督学习问题中的特征数n非常大，远远大于训练样本数m，但是我们怀疑其中只有一部分特征和学习问题相关，那么我们如何从中选择出我们希望的特征呢？ 给定n个特征，我们可以有2n种可能的模型(每个特征要么出现在模型中，要么不出现在模型中)。这样我们就将特征选择问题转化为规模为2n的模型选择问题。但是这样的计算量太大了，因此我们需要用一些启发式搜索方法进行特征选择。下面的这个算法称为前向搜索(forward search)： 初始化特征集合F为空 不断循环如下步骤，直到F的长度达到预设要求： (a). 将i从1到n进行遍历，如果i不在F中，令Fi = F ∪ {i}，然后用某种交叉验证算法计算Fi的误差 (b). 选择误差最小的Fi，并更新为F 输出最佳特征集合F 上述算法属于封装模型特征选择(wrapper model feature selection)。前向搜索是指每次循环都是从剩余未被选中的特征中选出一个最好的特征加到特征集合中。与之相对的还有后向搜索(backward search)，初始化特征集合F = {1, …, n}，每次循环都是从现有特征集合中选出一个最差的特征，然后将其从特征集合中移除，循环直到F的长度达到预设要求后才结束。 封装模型特征选择可以很好地工作，但是计算量比较大，时间复杂度达到了O(n2)。 过滤特征选择(filter feature selection)算法是另一个启发式搜索方法，拥有较低的计算复杂度。算法的主要思想是，对每一个特征xi，计算其与y的信息量S(i)，S(i)越大说明xi与y的相关性越强。计算完所有的S(i)后，选择前k个拥有最大S(i)的特征即可。 在实际应用中，S(i)通常选择为xi和y的互信息(mutual information)MI(xi, y)： 上述公式中的几个概率值都可以在训练集上计算得到。为了对这个公式有直观的感受，我们可以将互信息表示成KL散度(Kullback-Leibler (KL) divergence)的形式： 如果xi和y互相独立，那么p(xi, y) = p(xi)p(y)，那么这两个概率分布的KL散度为0，因此xi和y是不相关的，对应的S(i)较小。相反地，如果xi和y的相关性越大，那么KL散度越大，对应的S(i)也较大。 还有一个细节需要注意，计算完所有的S(i)后，应该如何选择k值？一个标准做法是使用交叉验证法来选择k值，不过这次的时间复杂度是线性的。 贝叶斯统计与规则化这一节我们再介绍一种可以减少过拟合发生的方法。 回顾之前我们在逻辑回归中使用了最大似然估计(maximum likelihood (ML))法来拟合参数，其公式为： 在上式中，我们把θ视为一个未知的常数，这一观点被认为是频率学派(frequentist)的观点。在频率学派的观点下，θ不是随机的，只是一个未知的变量，我们的任务就是通过某些方法估计出θ的值。 另一种看待θ的观点来自贝叶斯学派(Bayesian)。贝叶斯学派认为θ是随机的未知的变量，因而首先为θ指定一个先验概率(prior distribution)p(θ)。给定一个训练集S = {x(i), y(i)}i=1, …, m，我们可以计算出θ的后验概率(posterior distribution)： 上式中的p(y(i)|x(i), θ)的计算取决于我们使用的具体模型。比如在贝叶斯逻辑回归模型中， 对于一个新的输入x，我们可以用下面的公式进行预测： 如果我们要求期望值的话，可以用如下公式： 我们可以把上面步骤理解为“全贝叶斯预测”，因为我们在求后验概率时是对θ所有的值都计算了一遍，遗憾的是通常我们很难计算出这样的后验概率，因为对所有θ(通常是高维的)求积分是非常困难的。 因此，在实际应用中，我们需要对后验概率作一个近似估计，通常用单个θ的取值来替代整个后验概率。最大后验概率估计(maximum a posteriori(MAP))方法就采用了这个思想，其估计公式为： 可以发现，θMAP和θML的公式非常相似，除了在最大后验概率估计公式后面多了一项θ的先验概率。 在实际应用中，我们通常让θ服从高斯分布N(0,τ2I)。确定了这样的先验概率后，通常θMAP比θML的拟合效果更好，出现过拟合的概率更低。 总结 模型选择的常用方法是交叉验证，交叉验证具体又分为简单交叉验证、k重交叉验证和留一交叉验证等方法 特征选择的常用方法有封装模型特征选择和过滤特征选择。封装模型特征选择分为前向搜索和后向搜索，时间复杂度都为O(n2)；过滤特征选择的时间复杂度为O(n) 在参数拟合问题上有频率学派和贝叶斯学派两种观点。频率学派认为θ是固定的未知的变量，使用最大似然估计法；贝叶斯学派认为θ是随机的未知的变量，使用最大后验概率估计法；最大后验概率估计法拟合出来的参数通常拟合效果更好，出现过拟合的概率更低 参考资料 斯坦福大学机器学习课CS229讲义 pdf 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记8: 经验风险最小化","date":"2018-05-27T12:20:49.000Z","path":"2018/05/27/machine-learning-erm/","text":"偏差与方差当讨论线性回归时，我们提到过欠拟合和过拟合的问题。如下图所示，左图用的是y=θ0+θ1x的线性模型进行拟合，而右图用了更为复杂的多项式模型y=θ0+θ1x+…+θ5x5进行拟合。 使用五阶多项式模型进行拟合并不会得到一个很好的模型，因为即使在训练集上表现很好，我们不能保证在新的数据集上也能做出很好的预测。换句话说，从已知的训练集中学习的经验并不能推广到新数据集上，由此产生的误差就叫做这个假设函数的泛化误差(generalization error)。稍后我们会给出泛化误差更正式的定义。 上图最左边和最右边的两个图形都有很大的泛化误差，但这两种误差不太相同。左图的模型过于简单，无法准确描述训练集的数据，这种误差我们称为偏差(bias)，我们称这个模型是欠拟合(underfit)的。右图的模型过于复杂，对训练集的数据过于敏感，这种误差我们称为方差(variance)，我们称这个模型是过拟合(overfit)的。 通常我们需要在偏差和方差中进行权衡。如果我们的模型过于简单，并且参数较少，那么这个模型通常会有较大的偏差，但是方差较小。相反如果我们的模型过于复杂，并且参数较多，那么这个模型通常会有较大的方差，但是偏差较小。在上面这个例子里，使用二阶函数进行拟合效果最好，在偏差和方差中获得了较好的权衡。 经验风险最小化这一节我们正式给出泛化误差的定义以及如何在偏差和方差中进行权衡。在此之前，我们先介绍两个简单但很有用的引理。 联合边界(The union bound)引理：令A1, A2, …, Ak为k个不同的随机事件，那么： 在概率论里，联合边界通常被作为一个公理，因此也无需被证明，我们可以在直观上理解：k个随机事件中任何一个事件发生的概率至多是k个随机事件出现的概率总和。 Hoeffding不等式(Hoeffding inequality)引理：令Z1, Z2, …, Zm为m个服从伯努利分布B(φ)的独立同分布事件，即P(Zi = 1) = φ，P(Zi = 0) = 1 - φ，令φ^=(1/m)Σi∈[1,m]Zi为这些随机变量的平均值，对于任意的γ &gt; 0，有： 这个引理告诉我们，如果用m次随机变量的平均值φ^作为对φ的估计，那么m越大，两者的误差就越小。这个引理和我们在概率论中学习的大数定理是符合的。 基于上面两个引理，我们可以推导出学习理论中最重要的一些结论。 为了方便讨论，我们将问题限制在二元分类问题上，推导出的结论同样也适用于其他分类问题。 假设我们有一个个数为m的训练集S = {(x(i), y(i)); i = 1, …, m}，训练集的每个数据(x(i), y(i))都是服从概率分布为D的独立同分布。对于某个假设函数h，定义其训练误差(training error)，或者说经验风险(empirical risk)为： 训练误差描述的是假设函数h误判结果的比例。 另外，我们定义泛化误差(generalization error)为： 泛化误差描述的是假设函数h误判结果的概率。 考虑线性回归的例子，令假设函数hθ(x) = 1{θTx &gt;= 0}，那么我们如何选取参数θ使得假设函数最优呢？一个方法就是使经验风险最小，即选取： 我们把这个方法称为经验风险最小化(empirical risk minimization(ERM))，并把通过ERM产生的最优假设函数记为h^。 为了便于讨论，我们抛弃掉假设函数的参数化过程。定义假设函数类(hypothesis class)H是所有可能的假设函数的集合。比如对于线性分类，H就是： 现在ERM可以表示成如下的最优化问题： 有限假设空间首先我们考虑假设空间有限的情况，即H = {h1, …, hk}，H里包含k个假设函数，我们需要从k个假设函数中挑选出经验风险最小的那个函数。 我们的证明分两部分。首先证明可以用泛化误差来近似替代训练误差，其次证明泛化误差是有上边界的。 对于某个假设函数hi ∈ H，考虑一个概率分布为D的伯努利分布随机事件Z = 1{hi(x) != y}，Z的泛化误差是其分布的期望值，而Z的训练误差是所有事件的平均值，即： 根据Hoeffding不等式，可以得到： 这就证明了对于某个假设函数hi，只要m越大，泛化误差就越接近训练误差。接下来我们还要证明，对所有的假设函数h ∈ H，上述特性都成立。令事件Ai为|ε(hi) - ε(h^i)| &gt; γ，我们已经证明了P(Ai) &lt;= 2exp(-2γ2m)。根据联合边界引理，我们可以得到： 如果我们把两边同时减去1，可以得到： 也就是说，对所有的h ∈ H，泛化误差与训练误差相差γ的概率至少是1 - 2kexp(-2γ2m)，这个结论也被称为一致收敛(uniform convergence)。因此当m足够大时，我们可以用泛化误差来估计训练误差。 在刚才的讨论中，我们固定参数m和γ，给出P(|ε(hi) - ε(h^i)| &gt; γ)的边界。这里我们感兴趣的是三个变量，m，γ以及一个误差的概率(后面用δ表示)。我们可以固定其中两个变量来求解另一个变量的边界。 如果给定γ和δ &gt; 0，m需要取多大来保证上式成立？用δ = 2kexp(-2γ2m)代入求解，可得： 这个式子告诉我们为了满足误差的概率成立，m需要达到的最小值，此时m也被称为样本的复杂度(sample complexity)。这个式子也告诉我们，为了满足条件，m只和k成对数相关(logarithmic)。 类似的，固定m和δ来求解γ，我们可得： 下面我们来证明泛化误差是有上边界的。定义h* = arg minh∈Hε(h)是假设空间H里的最优假设函数。对于H里的任意假设函数h^，我们有： 上式中的第一步和第三步都是利用了一致收敛的结论，因此我们证明了某个假设函数h的泛化误差比最优假设函数的泛化函数最多相差2γ。 将前面几个结论整合到一起可以形成如下定理： 令|H| = k，对于任意的固定参数m和δ，如果泛化误差与训练误差一致收敛的概率至少为1 - δ，那么有： 这个式子可以用来量化我们之前讨论的偏差方差权衡问题。当我们选择一个更大的假设空间时，等式右边第一项将会变小(因为有可能寻找到更优的假设函数)，而等式右边第二项将会变大(因为k增大了)，因而我们可以将第一项看成偏差，第二项看成方差。 这个定理还有一个推论： 令|H| = k，对于任意的固定参数γ和δ，为了使ε(h^) &lt;= arg minh∈Hε(h) + 2γ的概率至少为1 - δ，那么m需满足： 无限假设空间我们已经在有限假设空间的情况下证明了一些有用的定理了，那么在无限假设空间中是否有相似的定理呢？ 在给出结论前，我们需要先介绍VC维的知识。 给定一个数据集S = {x(1), … x(d)}，数据集的每个点x(i) ∈ X，如果H可以对S进行任意标记(H can realize any labeling on S)，那么我们称H可以打散(shatter)S。也就是说，对任意标记 {y(1), … y(d)}，都存在h ∈ H使得h(x(i)) = y(i), i = 1, …, d。 给定一个假设空间类H，我们定义H的VC维(Vapnik-Chervonenkis dimension)，记为VC(H)，是H可以打散的最大样本集合个数。如果H可以打散任意大的样本集合，那么VC(H) = ∞。 举例来说，考虑如下三个点的样本集合： 如果H为二维线性分类器的集合，即h(x) = 1{θ0 + θ1x1 + θ2x2 &gt;= 0}，那么H是可以打散这个集合的。具体来说对于如下八种可能的情况，都可以找到一个“零训练误差”的线性分类器，如下图所示： 可以证明上述假设空间类H不能打散包含4个点的样本集合，因此H最多能打散的集合大小是3，即VC(H) = 3。 需要说明的是，如果这些点的排列方式在一条直线上，那么H是无法打散S的。这种情况如下图所示： 因此我们说VC(H) = d，只需证明H可以打散大小为d的某一个集合S即可。 介绍完VC维后，我们可以给出如下定理： 给定一个假设空间类H，令d = VC(H)，如果一致收敛的概率至少为1 - δ，那么对任意的h ∈ H，有： 也就有： 这就证明了，如果H的VC维是有限的，那么一致收敛就是有效的，只要m越大，泛化误差与训练误差越接近。 这个定理同样还有一个推论： 对所有的h∈H，为了使ε(h^) &lt;= arg minh∈Hε(h) + 2γ的概率至少为1 - δ，那么m需满足：m = Oγ,δ(d) 这个推论告诉我们，训练集的数据大小与H的VC维成正比。而对大多数假设函数类，VC维的大小近似与参数的个数成正比。将上述两个结论结合起来，我们可以得出：训练集的数据大小通常近似与参数的个数成正比。 总结 如果模型比较简单并且参数比较少，那么这个模型通常会有较大的偏差和较小的方差；如果模型比较复杂并且参数比较多，那么这个模型通常会有较大的方差和较小的偏差 训练误差描述了假设函数误判结果的比例，泛化误差描述了假设函数误判结果的概率；当数据集足够大时，可以用泛化误差来估计训练误差 在假设空间里选择一个使训练误差最小的假设函数，这个过程叫做经验风险最小化(ERM) 如果假设空间有限，样本复杂度与假设空间大小的对数成正比(m = Oγ,δ(log k))；如果假设空间无限，样本复杂度与假设空间的VC维成正比(m = Oγ,δ(d)) 参考资料 斯坦福大学机器学习课CS229讲义 pdf 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"HTTP/2 新特性浅析","date":"2018-05-06T14:27:12.000Z","path":"2018/05/06/http-2-introduction/","text":"HTTP发展简史HTTP/0.9 1991年发布 只支持GET命令 请求及返回值都是ASCII码 请求以换行符(CRLF)结束 返回值只支持HTML格式 服务器返回值之后立刻关闭连接 1GET /index.html HTTP/1.0 1996年发布 除了GET命令，还增加了POST和HEAD命令 服务器支持返回任意格式 请求和返回值除了包含数据部分，还增加头部信息(HTTP header) 返回值增加状态码(status code) 123GET / HTTP/1.0User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)Accept: */* 12345678910HTTP/1.0 200 OK Content-Type: text/plainContent-Length: 137582Expires: Thu, 05 Dec 1997 16:00:00 GMTLast-Modified: Wed, 5 August 1996 15:55:28 GMTServer: Apache 0.84&lt;html&gt; &lt;body&gt;Hello World&lt;/body&gt;&lt;/html&gt; HTTP/1.1 1997年发布 支持持久连接(Connection: keep-alive)，即TCP连接默认不关闭，可以被多个请求复用 支持管道机制(pipelining)，即一个TCP连接内可以同时发起多个请求 支持分块传输编码(chunked transfer encoding) 支持断点续传(Accept-Ranges) 支持更多命令，如PUT, PATCH, OPTIONS, DELETE 尽管支持复用TCP连接，但仍然会产生队头阻塞(Head-of-line blocking)问题 HTTP/2 2015年发布 2009年Google自行研发的SPDY在Chrome上验证成功后，被当作是HTTP/2的基础 完全采用二进制协议 支持多路复用(multiplexing) 支持头部压缩(header compression) 支持服务器推送(server push) 二进制协议HTTP/2之前的协议都是基于ASCII码，好处是可读性好，容易上手。其缺点是可选的空格以及多变的终止符给识别帧造成了一些困难。采用二进制协议可以使得帧的识别更简单，并且传输信息更高效。其缺点是不便于调试，这就需要我们使用相应的工具来理解二进制的内容。 HTTP/2完全采用二进制协议，头信息和数据体都是二进制的，统称为帧(frame)。下图展示了同一个请求在HTTP/1.1和HTTP/2的对应关系，可见请求在HTTP/2中分为了两部分：头部帧和数据帧。 一个帧的基本格式如下： 所有帧都由一个9字节的header和可变长的payload组成，各字段定义如下： Length: 表示payload的长度，payload的长度默认不能超过214 (16,384) ，除非修改SETTINGS_MAX_FRAME_SIZE为更大的值 Type: 表示帧的类型，比如0x0表示数据帧，0x1表示头部帧，类型不在规范里定义的帧将会被丢弃 Flags: 对于不同类型的帧，这个字段有不同的含义，比如在数据帧里，0x1表示这个frame是流的最后一帧(END_STREAM) R: 保留位，这一位必须置为0并且需要被忽略 Stream Identifier: 流ID，客户端发起的流ID必须是奇数的，服务端发起的流ID必须是偶数的 多路复用为了说明什么是多路复用，我们先需要明确下面几个概念： 流(stream): 已建立的连接内的双向字节流，可以承载一条或多条消息 消息(message): 与逻辑请求或响应消息对应的完整的一系列帧 帧(frame): HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流 这些概念的关系总结如下： 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP Header、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装 在HTTP/1.1中，如果客户端为了提高性能想要在一个TCP连接内同时发起多个请求，每个请求必须按顺序被服务器依次响应，如果某一个请求特别耗时，那么后面的请求将会被一直阻塞。 而在HTTP/2中，如果在一个TCP连接内同时发起多个请求，每个消息可以被拆成互不依赖的帧并且各帧之间交错发送，然后在另一端重新把帧组装起来。这个特性就叫做多路复用。 上图展示了同一个连接内并行的多个数据流。客户端正在向服务器传输一个数据帧(数据流5)，与此同时，服务器正向客户端交错发送数据流1和数据流3的一系列帧。因此，一个连接上同时有三个并行数据流。 头部压缩每个HTTP请求时都会承载一组表头。在HTTP/1.x中表头是以纯文本形式传输，通常需要500~800字节的开销，如果有cookie的话甚至会达到上千字节。为了减少这种开销并且提升性能，HTTP/2使用了HPACK算法进行压缩，具体来说包含了如下两种简单并强大的技术： 头部字段使用静态Huffman编码，如果编码后使得字符反而变长了，那么不采用Huffman编码 客户端和服务器同时维护并更新一个索引表，如果传输的值在索引表里，那么使用索引值作为传输的值。索引表分为静态表和动态表两部分，静态表在规范里定义，包含了一些常用的字段，动态表初始为空，在连接过程中动态更新 如上图所示，最左边是原始的请求头，第一行的:method GET通过查找静态索引表得到索引值为2，所以HPACK算法将其编码为2。最后第二行的user-agent Mozilla/5.0 ...不在静态索引表里，但在动态索引表里查到索引值为62，所以HPACK算法将其编码为62。最后一行的两个字段均未在索引表里查到，所以分别对其进行Huffman编码。 服务器推送HTTP/2新增的另一个强大的功能是允许服务器除了可以响应客户端请求，还可以向客户端推送额外的资源。 通常当我们请求一个网页时，客户端解析HTML源码，发现有js或css等其他静态资源，然后再发起请求下载静态资源。而实际上，当客户端请求网页后，服务器完全可以预判客户端接下来要请求相关的静态资源，那为什么不让服务器提前推送这些资源，从而减少额外的延迟时间呢？HTTP/2为此提出了服务器推送机制，服务器端可以通过发起PUSH_PROMISE帧告知客户端，客户端收到服务器想要推送资源的意图后，可以决定是否接收推送。 事实上，如果你在网页中内联CSS或Javascript，那么你已经体验过服务器推送了。使用HTTP/2，我们不仅可以获得相同效果，还可以获得更多的性能优势： 客户端可以缓存推送资源 推送资源可以被不同页面重用 推送资源可以与其他资源复用 推送资源可以由服务器设定优先级 推送资源可以被客户端拒绝(非强制推送) 服务器推送功能虽然很强大，但在实际使用中还需要考虑一些问题。第一个问题是如果客户端已经有缓存了，那么推送资源就是一种浪费。一种解决方法是只在用户第一次访问的时候推送资源。第二个问题是目前我们一般把静态资源放在CDN上，目前大部分CDN还不支持服务器推送，那么CDN和服务器推送到底哪个效果更好，这个可能还需要一些测试数据来做评判。 参考资料 Hypertext Transfer Protocol version 2 - RFC7540 HPACK - Header Compression for HTTP/2 - RFC7541 An Excerpt from High Performance Browser Networking: HTTP/2 Homepage for HTTP/2 Introduction to HTTP/2 HTTP 协议入门 HTTP/2 服务器推送（Server Push）教程","tags":[{"name":"HTTP/2","slug":"HTTP-2","permalink":"http://www.secondplayer.top/tags/HTTP-2/"}]},{"title":"机器学习笔记7: 支持向量机(下)","date":"2018-04-30T12:39:28.000Z","path":"2018/04/30/machine-learning-svm-part-two/","text":"上一篇文章中我们已经根据拉格朗日对偶性推导出了SVM最优化公式。而在这一篇文章中，我们将会从SVM最优化公式中引出核函数(kernels)的概念，由此给出在高维空间下更高效应用SVM的算法，然后利用正则化解决线性不可分与异常点的问题，最后介绍用于高效实现SVM的序列最小优化(sequential minimal optimization)算法。 核函数在线性回归的问题中，我们曾举过预测房价的例子，输入特征x是住房面积。假设我们为了提高预测准确性，希望用x2，x3作为特征来建模。为了区别这两类变量，我们把原始的输入变量称为属性(attribute)，对原始变量映射后的项叫做特征(feature)。定义φ为特征映射(feature mapping)函数，在这个例子中，我们有： 为了应用SVM算法，我们需要将算法中出现x的地方替换成φ(x)。由于算法可以被完全写成向量内积的形式，这意味着我们可以将其替换为&lt;φ(x), φ(z)&gt;。给定一个特征映射函数，我们定义核函数(kernels)为： 因此，在算法中我们可以把都替换成K(x, z)。给定φ，我们通过求φ(x)和φ(z)的内积来计算K(x, z)。有趣的是，即使φ(x)可能因为维度较高导致计算起来比较耗时，而计算K(x, z)并不是很耗时。在这种情况下，通过在算法中引入K(x, z)，可以使得SVM算法的计算量大大减少。 我们来举个例子看一下，假设 我们可以计算出： 对比K(x, z)的定义，可得到特征映射函数φ为(当n=3时)： 可见计算φ(x)的时间复杂度是O(n2)，而计算K(x, z)的时间复杂度是O(n)。 再考虑一个例子，假设 对比K(x, z)的定义，可得到特征映射函数φ为(当n=3时)： 推广到更一般的形式，假设K(x, z) = (xTz + c)d，计算φ(x)的时间复杂度是O(nd)，而计算K(x, z)的时间复杂度仍旧是O(n)。当维度较高时，核函数的优势更加明显。 另一个常用的核函数是高斯核(Gaussian kernel)，其特征映射函数φ可以映射到无限维。高斯核函数为： 我们接下来的一个问题就是给定一个函数K，它是否能成为一个合法的核函数，也就是说是否存在一个映射函数φ使得K(x, z) = &lt;φ(x), φ(z)&gt;? 假设K是一个合法的核函数，对于一个包含有限个点的集合{x(1), x(2), …, x(m)}，定义核矩阵(Kernel matrix)K，矩阵的每个元素Kij = K(x(i), x(j))。注意由于核函数和核矩阵的关系密切，我们使用了相同的符号K来表示它们。 当K是合法的核函数时，可证明Kij = Kji，因此K是对称矩阵。此外，定义φk(x)表示向量φ(x)的第k个元素，我们也能证明： 综上我们可得出结论，如果K是合法的核函数，那么对应的核矩阵K是对称半正定(symmetric positive semidefinite)矩阵。这个结论反过来也成立，即“K是合法的核函数”是“核矩阵K是对称半正定矩阵”的充分必要条件，这个结论被称为Mercer定理(Mercer Theorem)。 核函数在机器学习中有广泛的应用。比如在数字识别问题中，我们需要根据一张图片(16*16像素)识别出数字(0-9)。如果把每个像素作为特征值，那么会有256个特征值，使用核函数(K(x, z) = (xTz)d或者高斯核)后可以使SVM的性能大大提升。 正则化与线性不可分的情况到目前为止，我们在推导SVM过程中都是基于“数据是线性可分的”这个假设。尽管用函数φ将特征映射到高维可以增加数据线性可分的可能性，但这个假设不能保证总是成立。此外，还有一种情况是如果数据里有异常点(outlier)，那么得到的超平面可能并不是我们想要的结果。比如左下图显示了一个最优超平面，右下图里增加了一个异常点使得最优超平面的间隔变小了，影响了分类器的性能。 为了使SVM算法在线性不可分的情况下正常工作，并且对异常点不那么敏感，我们采用l1正则化(l1 regularization)方法修改优化目标为： 通过增加ξi项，我们允许函数间隔小于1，并且当函数间隔小于1的时候，我们在目标函数增加Cξi的代价。 同样，我们对该问题构造拉格朗日算子： 其中αi和ri是拉格朗日乘数。我们不详细展开推导了，最后我们可以得到对偶问题为： 通过求解该最大化问题可以得到α*，然后代入回原始问题可得到其他参数。另外由于采用了l1正则化，原来αi &gt;= 0的限制变成了 0 &lt;= αi &lt;= C。此外，该问题的KKT对偶互补条件为： 最后我们还剩下一个问题没有讲，那就是如何求解最大化W(α)的方法，这个是我们下面要介绍的内容。 坐标上升算法首先我们考虑没有任何约束条件的优化问题： 其中W是以α为参数的函数。之前在优化问题中我们介绍过梯度下降法和牛顿方法，在这个问题里我们使用坐标上升(coordinate ascent)算法。 算法的核心思想是，每次固定一个参数αi，然后使W关于αi作优化调整。在这个算法里，我们依次选取α1到αm作优化，然后不断循环直到结果收敛为止。这个算法的一个优化方向是，调整αi参数选取的顺序，每次选择使得W(α)增加幅度最大的αi作为下一个参数。 上图是一个优化二次函数的等高线示意图。坐标初始点在(-2, 2)，可以看到每次优化只在一个维度方向上进行优化。 序列最小优化算法回到我们SVM的对偶问题上来，我们要求解的优化问题为： 利用坐标上升算法的思想，我们每次固定一个参数αi进行优化是否可行？答案是不可行，假设我们固定α1，根据约束条件(19)，可得： 两边都乘以y(1)，可得： 所以α1受到其余αi参数的控制，当α2, …, αm不变时，α1也不会改变。 因此如果我们要使用坐标上升算法的话，需要一次更新两个参数。具体来说就是，每次选取两个参数αi和αj进行更新，使W关于αi和αj作优化调整，然后不断循环直到结果收敛为止。 这个算法被称为序列最小优化(sequential minimal optimization, SMO)算法，最早由John Platt提出，相关论文可以在这里找到。 为了判断算法的收敛性，我们可以检查KKT条件是否满足tol参数，具体方法在John Platt关于SMO的论文里有阐述。 SMO算法之所以高效就在于每次更新两个参数αi和αj的操作本身就很高效，我们具体来描述一下。 根据等式(19)，我们有： 既然等式右边的参数是固定的，我们就用一个常量ζ来表示： 我们可以把α1和α2的约束条件画成下面的图。 根据约束条件(18)，α1和α2必须限制在[0,C]×[0,C]的方块内。另外α1和α2必须满足图中直线的约束。α2要满足L ≤ α2 ≤ H的条件，其中L, H是α2的上下边界。 根据等式(20)，我们把α1写成是关于α2的函数: 那么目标函数W可以表示为： 把α3, …, αm视为常量，可以看出W是关于α2的二次函数。如果我们不考虑限制条件(18)，那么通过求导就可以求出使这个二次函数最大化的参数，记为α2new, unclipped。再把限制条件(18)考虑进来，我们可以得到： 最后，根据α2new的值以及等式(20)，可以求得α1new的值。 关于这个算法还有其他一些细节，但我们不会在这里一一阐述，有兴趣的读者可以自行查看Platt的论文。 总结 引入核函数的概念后，通过把数据映射到高维空间，有概率可解决原始空间中线性不可分的问题，并且可以使SVM算法更高效 Mercer定理：“一个核函数是合法的”是“核函数对应的核矩阵是对称半正定矩阵”的充分必要条件 为了使SVM算法在线性不可分的情况下正常工作，并且对异常点不那么敏感，可以采用l1正则化的方法 John Platt提出的SMO算法，可以高效求解SVM的对偶问题，其基本思想是利用了坐标上升算法 参考资料 斯坦福大学机器学习课CS229讲义 pdf 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记6: 支持向量机(上)","date":"2018-04-15T13:06:29.000Z","path":"2018/04/15/machine-learning-svm-part-one/","text":"在接下来的两篇文章里，我们会着重介绍支持向量机(Support Vector Machine)算法，以下简称为SVM。SVM可以称得上是监督学习里最优秀的算法了，在诸如文本分类，图像识别，生物序列分析等领域有很多的应用。 本篇文章首先介绍间隔(margin)的概念，然后给出最优间隔分类器(optimal margin classifier)的定义，同时将该问题转化为一个凸优化(convex optimization)问题，随后补充介绍拉格朗日对偶性(Lagrange duality)的知识，并由此推导出最优间隔分类器的对偶问题。 符号表示为了使SVM的描述更简单，我们需要对之前的符号表示做一些修改。对于一个二元线性分类器，特征向量是x，输出分类是y。之前y的取值是0和1，现在我们把取值修改为-1和1。之前假设函数h(x)是以θ作为参数，即： 现在我们使用w和b作为参数，即： 其中，如果z &gt;= 0，那么g(z) = 1，否则g(z) = -1。用w和b表示可以显式地让我们把截距(intercept)b从其他参数中分离出来。对比两种h(x)的定义，b相当于原来的θ0，w相当于剩余的参数[θ1, θ2, …, θn]T。 注意，由于g(z)的定义变了，现在我们的分类器可以直接输出1或者-1，而不是像逻辑回归那样先求出y = 1的概率，再根据概率预测输出。 函数间隔和几何间隔下图是一个线性分类器的图示，图中显示了训练集的两个分类数据(分别用圈和叉表示)，以及一个决策边界(decision boundary)将两类数据分割开。图中的直线是wTx + b = 0，也被称为超平面(hyperplane)。 图中有三个点A、B和C，其中A离超平面最远，C离超平面最近，因而我们认为A比C有更大的可能性属于叉的分类。那么，我们应该确定这个超平面呢？从直觉上看，这个超平面应该使每个点离超平面的间隔都尽可能大。 为了确定这个超平面，我们需要正式给出间隔(margin)的定义。对于训练数据(x(i), y(i))，我们定义它与超平面(w, b)的函数间隔(functional margin)为： 如果y(i) = 1，那么wTx + b必须是正数，并且wTx + b越大，函数间隔越大；相反地，如果y(i) = -1，那么wTx + b必须是负数，并且wTx + b越小，函数间隔越大。因而函数间隔越大，分类预测的可信度越高。 有了单个训练数据的函数间隔的定义，我们可以定义整个训练数据集的函数间隔是所有训练数据的函数间隔的最小值，即： 函数间隔虽然可以表示分类预测的可信度，但它有一个缺点：如果我们成比例地增大w和b(比如把w和b替换成2w和2b)，那么函数间隔的值也会成比例地增大，然而超平面本身并没有改变，因此这样是无意义的。直觉上看，我们需要对参数作一些约束，比如限制||w|| = 1，而这就引出了几何间隔(geometric margin)的定义。 几何间隔实际上就是数据点到超平面的垂直距离，比如上图中点A的几何间隔就是A到超平面的距离AB，根据平面几何的知识可以求出数据点(x(i), y(i))到超平面(w, b)的距离为： 上式就是几何间隔的定义。可以看到，如果||w|| = 1，那么几何间隔就等于函数间隔。 另外如果我们任意缩放w和b，那么几何间隔并不会随之改变。 同样地，整个训练数据集的几何间隔是所有训练数据的几何间隔的最小值，即： 一般地，函数间隔和几何间隔有如下关系： 最优间隔分类器的定义上面我们讨论到，寻找最优超平面的条件应该使每个点离超平面的间隔都尽可能大，因而最优超平面也被称为最优间隔分类器(optimal margin classifier)。并且由于“任意缩放w和b，几何间隔并不会随之改变”，上述讨论中的间隔应该使用几何间隔，所以最优间隔分类器问题可以定义为： 这个优化问题解决起来比较棘手，因为目标函数是非凸函数，我们没有办法用现成的软件可以解决这个问题。再次考虑“任意缩放w和b，几何间隔并不会随之改变”这个结论，我们可以对该问题增加一个约束：函数间隔等于1，并且最大化1 / ||w||等价于最小化||w||2 ，那么问题被转化为： 这样我们就把原始问题转化成了一个凸优化问题，而这个问题可以用现成的二次规划(quadratic programming)软件来求解。 拉格朗日对偶性这一部分我们介绍拉格朗日对偶性(Lagrange duality)，其核心思想是通过拉格朗日对偶性可以将原始问题转化为对偶问题，而对偶问题通常比较容易求解。 考虑如下优化问题： 即最小化函数f(w)，并且满足l个等式约束(equality constraint)条件hi(w) = 0。定义拉格朗日算子(Lagrangian)： 即等于原始目标函数加上约束函数的线性组合，其中βi是拉格朗日乘数(Lagrange multipliers)。分别求L关于w和β的偏导数即可求出原始问题的解： 上述的优化问题只包含等式约束，而更广义的优化问题还包含不等式约束(equality constraint)。下面我们定义这个广义优化问题，也称为原始优化问题(primal optimization problem)： 即最小化函数f(w)，并且满足l个等式约束条件hi(w) = 0和k个不等式约束条件gi(w) &lt;= 0。定义广义拉格朗日算子(generalized Lagrangian)： 其中αi和βi是拉格朗日乘数。定义： 下标p表示原始(primal)问题，可以证明： 因此当w满足原始约束条件时，原问题等价为： 为了后面表述方便，定义p*是原始问题的最优解： 我们再考虑另一个稍微不同的问题，定义： 下标D表示对偶(dual)问题，注意在原始问题中是关于参数α和β求最优解，而对偶问题是关于参数w求最优解。定义对偶优化问题(dual optimization problem)： 和原始优化问题相比，对偶优化问题把max和min的顺序交换了一下。同样为了表述方便，定义d*是对偶问题的最优解： 原始问题与对偶问题的关系如下： 事实上一个函数的max min值总是小于等于它的min max值，这里我们不作证明。而在某些情况下，我们有： 这种情况下求解原始问题等价于求解对偶问题。下面我们不加证明地给出使得p* = d*成立的条件。 假设f和gi是凸函数，hi是仿射(affine)函数(即存在ai和bi使得hi(w) = aiTw + bi)，并且gi是严格可执行的(strictly feasible)(即存在w使得对于所有gi(w)","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记5: 朴素贝叶斯算法","date":"2018-03-26T14:22:44.000Z","path":"2018/03/26/machine-learning-naive-bayes/","text":"朴素贝叶斯模型在上节介绍的GDA方法中，输入特征x是连续型随机变量。现在我们介绍一个算法用于处理x是离散值的情况。 我们以邮件分类为例来介绍这个算法，邮件分类问题是文本分类(text classification)问题的一个子集。这里我们只考虑把邮件分为两类：垃圾邮件(spam email)和非垃圾邮件(non-spam email)。 我们把邮件中所有出现的单词的集合称为词汇表(vocabulary)。首先我们构造特征向量xi，xi的长度等于词汇表里单词的个数。如果词汇表中第i个单词出现在某封邮件中，那么xi=1，否则xi=0，比如： 上图表明这封邮件里包含a和buy这两个单词，但不包含aardvark，aardwolf，zygmurgy这三个单词。 构建完特征向量后，我们需要对p(x|y)进行建模。假设词汇表里有50000个单词，那么x是50000维的向量且每个元素在0和1内取值，这样可能的结果就有250000种，如果用多项式分布建模的话，就会有250000 - 1个参数，这显然是个天文数字。 为了简化问题，我们就需要做一些假设。我们假设给定y的情况下，xi之间是条件独立的，这个假设称为朴素贝叶斯假设(Naive Bayes assumption)。举例来说，如果y=1表示垃圾邮件，buy是第2087个单词，price是第39831个单词，那么在已知该邮件是垃圾邮件的情况下，“buy出现在该邮件中”和“price出现在该邮件中”这两件事是互不相关的。用形式化的方法表述就是，p(x2087|y)=p(x2087|y, x39831)。注意，我们不是说x2087和x39831是互相独立的，而是说在给定y的情况下x2087和x39831是条件独立的。 因此我们可以作如下推导： 其中第一个等号基于条件概率链式法则，第二个等号基于朴素贝叶斯假设。需要说明的是，尽管朴素贝叶斯假设是个比较强的假设，但在实际问题中表现的效果很好。 我们的模型由φi|y=1 = p(xi=1|y=1)，φi|y=0 = p(xi=1|y=0)和φy = p(y=1)这三个参数决定，其似然函数为 通过最大化似然函数，可以求得： 上式中的∧表示逻辑上的与(and)。这个公式可以从直观上进行解释，比如φi|y=1就是第j个单词出现在垃圾邮件中的次数除以垃圾邮件的总个数。 所有参数确定后，对一个新特征x作预测，我们可以计算出： 根据p(y=1|x)是否大于0.5来判断新邮件是否是垃圾邮件。 最后，尽管上面我们的x取值只是0或1，但实际上可以把它扩展到多个离散值的情况。另外即使x是连续取值的，我们可以通过离散化(discretize)，即按一定的区间将连续值映射到离散值，然后应用朴素贝叶斯算法。 比如对于房价预测问题，我们可以按照上表把住房面积按一定区间离散化，如果住房面积是890，那么对应的特征值xi就是3。一般来说，如果连续型随机变量不能用多元正态分布建模(不能使用GDA)，那么将其离散化并采用朴素贝叶斯建模是一个更好的算法。 拉普拉斯平滑处理朴素贝叶斯算法对大多数问题都有很好的表现，但是我们还需要对其作一些修正使得它在文本分类问题中表现地更出色。 假设NIPS是词汇表里的第35000个单词，但是这个单词从未在训练数据中出现过，因此： 所以预测一个包含单词NIPS的邮件是否为垃圾邮件，我们计算得到： 这是由于每一项乘积里都有p(x35000|y) = 0，因此分子分母都为0，这使得我们无法进行计算。 这个问题从广义上来讲就是，仅仅因为一个事件没有在训练集中出现就预测它的概率为0不是一个好主意。对于φi = p(z=i)，之前根据最大似然估计的结果为： 为了避免某些φj等于0，我们可以使用拉普拉斯平滑处理(Laplace smoothing)，修正参数如下： 我们在原参数基础上，分子上加了1，分母上加了k。注意修正之后，所有φj之和仍然为1(j从1到k取值)。并且所有的φj都不为0，解决了之前的问题。 将拉普拉斯平滑处理代入到朴素贝叶斯算法，我们得到修正后的参数： 文本分类的事件模型朴素贝叶斯算法在很多文本分类问题中都表现地不错，但还有个与之相关的算法表现地更出色。 在文本分类的特定领域，朴素贝叶斯算法使用的是多元伯努利事件模型(multi-variate Bernoulli event model)。在该模型中，我们假设下一封邮件的发送方是随机的发送者(可能是垃圾邮件制造者或者是正常发件人)，然后发送方遍历整个字典，然后决定是否将单词i写到邮件中，每个单词i写入的概率p(xi=1|y) = φi|y互相独立。因此，这封邮件出现的概率为： 我们再介绍另一个模型，称之为多项式事件模型(multinomial event model)。这个模型引入了一套不同的符号和特征，xi表示邮件里第i个单词的在字典中的位置，xi在1到|V|中取值，|V|是词汇表(字典)的大小。一封由n个单词组成的邮件由长度为n的向量表示(x1, x2, …, xn)。比如，某封邮件的开头为”A NIPS …”，那么x1=1(a是字典里第1个单词)，x2=35000(NIPS是字典里第35000个单词)。 在多项式事件模型中，我们仍随机选择发送者(和多元伯努利事件模型一样，概率是p(y))，然后发送者根据多项式分布决定第一个单词x1出来(概率是p(x1|y))，再以同样的方式决定后续的单词x2, …, xn，直到选出n个单词构成这封邮件。因此，在该模型下邮件出现的概率为： 注意这个公式和在多元伯努利事件模型下推导出来的公式非常类似，但实际上这里的每一项都表示不同的含义，尤其是xi|y现在服从多项式分布，而不是伯努利分布。 该模型的参数和之前一样，它们是 φk|y=1 = p(xj=k|y=1)，φk|y=0 = p(xj=k|y=0)和φy = p(y)。注意对于任意的j，p(xj|y)的值都是一样的，也就是说单词在邮件中出现的位置与概率无关。 给定训练数据集(x(i), y(i))，其似然函数为： 通过最大化似然函数，可以求得： 应用拉普拉斯平滑，我们在分子上加1，在分母上加|V|，修正后的参数为： 尽管朴素贝叶斯算法不是最好的分类算法，但它的效果却是惊人地好。由于它的简单和易于实现的特性，我们通常把它作为首选试验的算法。 总结 在分类问题中常用的分类算法是朴素贝叶斯算法，模型需要满足朴素贝叶斯假设，即给定y的情况下，xi之间是条件独立的 如果x是连续型随机变量，可以通过离散化后应用朴素贝叶斯算法；对于某些不能使用GDA建模的模型，该方法是一个更好的算法 为了解决朴素贝叶斯算法中某些参数为0导致预测失效，可以采用拉普拉斯平滑对参数修正 文本分类的两种事件模型：多元伯努利事件模型和多项式事件模型，后者通常效果更好 参考资料 斯坦福大学机器学习课CS229讲义 pdf 网易公开课：机器学习课程 双语字幕视频 上 下","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记4: 生成学习算法","date":"2018-03-11T12:40:01.000Z","path":"2018/03/11/machine-learning-gla/","text":"生成学习算法目前为止，我们主要讨论的学习算法基于p(y|x;θ)进行建模，即给定x的情况下y的条件分布。比如在逻辑回归里我们基于p(y|x;θ)推导出hθ(x)=g(θTx)，其中g(z)是sigmoid函数。这次我们来介绍另一种类型的学习算法。 考虑这样一个分类问题，根据动物的某些特征用来区分该动物究竟是大象(y=1)还是狗(y=0)。之前的回归算法可能通过梯度上升算法求出一条直线，也就是决策边界(decision boundary)，来区分大象和狗。对于一个新的动物，看它落到直线的哪一边就能做出相应的预测。 另一种方法是，我们挑选出大象的数据，单独对大象进行建模；对狗也一样，单独对狗进行建模。对于一个新的动物，分别对大象的模型和狗的模型进行匹配，看哪个匹配得更像，进而做出相应的预测。 像逻辑回归这样对p(y|x)进行建模的算法称为判别学习算法(discriminative learning algorithms)。而这次我们介绍的对p(x|y)进行建模的算法称为生成学习算法(generative learning algorithms)。拿刚才的分类问题举例，如果y=1表示动物是大象，y=0表示动物是狗，那么p(x|y=0)就表示对狗的特征进行建模，p(x|y=1)就表示对大象的特征进行建模。 p(x|y)和p(y|x)的关系可以用贝叶斯规则(Bayes rule)描述： 由于p(x)是一个与y无关的值，所以为了让p(y|x)取最大值，可以忽略分母的值，即： 多元正态分布在介绍下面的算法之前，我们先简单讨论一些多元正态分布(multivariate normal distribution)的知识。 多元正态分布，又称多元高斯分布，是一元高斯分布的在向量形式的推广。对一个均值(mean vector)为μ，协方差矩阵(covariance matrix)为Σ的n维多元正态分布，其概率密度函数为： 如果一个随机变量X服从多元正态分布N(μ,Σ)，它的期望值由μ决定，即： 协方差矩阵Cov(X)=E[(X-E(X))(X-E(X))T]=Σ。下面我们用几张图说明参数μ和Σ对分布的影响。 上图最左面的图形表示一个μ=0，Σ=I(2*2的单位矩阵)的标准正态分布(standard normal distribution)。中间的图形表示的是μ=0，Σ=0.6I的正态分布。右边的图形表示的是μ=0，Σ=2I的正态分布。由此可见，Σ越大，图形更“扩散(spread-out)”，Σ越小，图形更“压缩(compressed)”。 上图的三个图形表示μ=0，Σ分别如下所示的正态分布： 由此可见，增加Σ非对角线(off-diagonal)上的值，图形向45度角方向上变得更“压缩(compressed)”了。 最后我们看下参数μ对图形的影响： 上图的分布参数Σ=I，μ的值分别如下： 综上，μ的值决定了中心的位置，Σ的值决定了分布的幅度。 高斯判别分析假设在我们的分类问题中，x是连续的随机变量，p(y)服从伯努利分布，p(x|y)服从多元正态分布，这样的模型称为高斯判别分析(Gaussian Discriminant Analysis, GDA)模型。具体来说： 它们对应的概率分布为： 这里我们模型的参数有φ，Σ，μ0，μ1。注意，尽管两个多元正态分布有不同的均值μ0和μ1，但它们有相同的协方差矩阵Σ。这个模型的对数似然函数为： 通过最大化l，我们可以求得各参数如下： 下面我们用图形来更直观地理解一下： 上图给出了训练数据，以及两个高斯分布的等高线图。两个分布的形状相似(因为有相同的协方差矩阵Σ)，但位置不同(因为均值μ不同)。图中也给出了一个直线，表示p(y=1|x) = 0.5时的决策边界。在边界的一边我们认为y=1是概率最大的，而另一边我们认为y=0是概率最大的。 高斯判别分析与逻辑回归的关系GDA模型和逻辑回归之间的关系很有趣。如果我们把p(y=1|x;φ,Σ,μ0,μ1)看作是关于x的函数，我们可以将其表示成如下形式： 其中θ可以写成关于φ,Σ,μ0,μ1的函数。上式正好是逻辑回归的表达形式。 如果p(x|y)服从多元正态分布，那么p(y|x)可表达成逻辑回归的形式。相反地，如果p(y|x)可表达成逻辑回归的形式，那么不代表p(x|y)服从多元正态分布。这说明GDA比逻辑回归需要更加严格的模型假设。当GDA模型假设成立时，GDA的拟合效果比逻辑回归更好；而当假设不成立时，逻辑回归的拟合效果更好。 另外在补充一点，如果p(x|y)服从指数分布族，那么p(y|x)也可表达成逻辑回归的形式。但是用GDA去拟合非高斯分布的数据，它的预测效果是不可捉摸的，效果可能好也可能不好。 总结 对p(y|x)进行建模的算法称为判别学习算法，例如逻辑回归；对p(x|y)进行建模的算法称为生成学习算法，例如高斯判别分析(GDA) 对一个均值为μ，协方差矩阵为Σ的多元正态分布，μ值决定了中心的位置，Σ值决定了分布的幅度 如果p(x|y)服从多元正态分布，那么p(y|x)可表达成逻辑回归的形式；相反地，如果p(y|x)可表达成逻辑回归的形式，那么不代表p(x|y)服从多元正态分布 GDA需要更加严格的模型假设，当假设成立时，GDA的拟合效果比逻辑回归好，否则逻辑回归的拟合效果更好；逻辑回归的模型假设相对弱一点，这使得它在实际应用中更普遍 参考资料 斯坦福大学机器学习课CS229讲义 pdf 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记3: 广义线性模型","date":"2018-02-13T08:33:18.000Z","path":"2018/02/13/machine-learning-glm/","text":"牛顿方法之前我们在最大化对数似然函数l(θ)时用到了梯度上升法，现在我们介绍另一种方法。 我们先来看下如何用牛顿方法(Newton’s Method)求解θ使得f(θ)=0。如下图所示，首先我们选取一个初始点，比如说令θ=4.5，然后作出f(θ)在该点的切线，这条切线与x轴相交的点θ=2.8作为下一次迭代的点。下右图又一次重复了一轮迭代，f(θ)在θ=2.8处的切线与x轴相交于θ=1.8处，然后再次迭代到θ=1.3处。 以此类推，我们得到迭代规则如下： 牛顿方法可以找到θ使得f(θ)=0，那么如何把它应用到最大化l(θ)上呢？当l(θ)达到最大点时，其导数为0，因此问题转化为找到θ使得l’(θ)=0。所以，令f(θ)=l’(θ)，我们推导出迭代规则： 上式中的θ是参数为实数的情况，当θ为向量时，我们可以推导出更通用的公式： 其中∇θl(θ)是指l(θ)的梯度，H是一个n n的矩阵，被称为*海森矩阵(Hessian Matrix)。 和梯度下降法相比，牛顿方法收敛的速度更快，迭代的次数也更少。但是牛顿方法每次迭代的计算量更大，因为每次都要计算一个n阶矩阵的逆。总体而言，当n不是很大时牛顿方法计算的速度更快。当牛顿方法用来求解最大化对数似然函数l(θ)时，这个方法也被称为Fisher Scoring。 指数分布族到目前为止，我们分别学习了分类(classification)和回归(regression)两类问题。在回归问题里，我们假设p(y|x;θ)服从高斯分布N(0,σ2)；在分类问题里，我们假设p(y|x;θ)服从伯努利分布B(φ)。后面我们会看到，这两类问题可以被统一到一个更通用的模型，这个模型被称为广义线性模型(Generalized Linear Models, GLM)。在介绍GLM前，我们先引入一个概念：指数分布族(exponential family)。 指数分布族是指一类可以被表示为如下形式的概率分布： 其中η被称为分布的自然参数(natural parameter)，或者是标准参数(canonical parameter)；T(y)是充分统计量(sufficient statistic)，通常T(y)=y；a(η)是对数分割函数(log partition function)。e-a(η)通常起着归一化的作用，使得整个分布的总和/积分为1。 如果固定参数T, a, b，就定义了一个以η为参数的函数族。当η取不同的值，我们就得到一个不同的分布函数。 现在我们来证明高斯分布(Gaussian distribution)和伯努利分布(Bernoulli distribution)都属于指数分布族。 对于伯努利分布B(φ)，其y值为0或1，因而有p(y=1;φ)=φ; p(y=0;φ)=1-φ 。所以可推导p(y;φ)如下： 对比指数分布族的定义，可得η=log(φ/(1-φ))，进而可得φ=1/(1+e-η)，而这正是sigmoid函数的定义。同样对比其他参数，可得： 综上可得，伯努利分布属于指数分布族，且φ的形式与sigmoid函数一致。 接下来我们继续来看高斯分布N(μ,σ2)。回忆下之前推导线性回归的时候，σ2的值与θ和hθ(x)无关，因此为了简化证明，我们令σ2=1，所以可推导p(y;μ)如下： 对比指数分布族的定义，进而可得： 因而我们证明了高斯分布也属于指数分布族。事实上，大多数概率分布都属于指数分布族，我们列举一些如下： 多项式分布(Multinomial distribution)：对有k个离散结果的事件建模 泊松分布(Poisson distribution)：描述单位时间内独立事件发生次数的概率 伽马分布(Gamma distribution)与指数分布(Exponential distribution)：描述独立事件的时间间隔的概率 β分布(Beta distribution)：在(0,1)区间的连续概率分布 Dirichlet分布(Dirichlet distribution)：分布的分布(for distributions over probabilities) 广义线性模型介绍完指数分布族后，我们开始正式介绍广义线性模型(GLM)。对回归或者分类问题来说，我们都可以借助于广义线性模型进行预测。广义线性模型基于如下三个假设： 假设1: p(y|x;θ) 服从以η为参数的指数分布族中的某个分布 假设2: 给定x，我们的目标是预测T(y)的期望值，大多数情况下T(y)=y，所以假设函数可以写为h(x)=E[T(y)|x] 假设3: η与x是线性相关的，即η=θTx 依据这三个假设，我们可以推导出一个非常优雅的学习算法，也就是GLM。接下来我们分别看几个通过GLM推导出来的算法。 最小二乘法假设p(y|x;θ)服从高斯分布N(μ,σ2)，我们可以推导如下： 上式中第一个等号来自假设2，第二个等号是高斯分布的特性，第三个等号来自上一节中我们已经证明了η=μ，第四个等号来自假设3。 逻辑回归假设p(y|x;θ)服从伯努利分布B(φ)，我们可以推导如下： 上式中第一个等号来自假设2，第二个等号是伯努利分布的特性，第三个等号来自上一节中我们已经证明了φ=1/(1+e-η)，第四个等号来自假设3。 这里多介绍一些术语：将η与原始概率分布中的参数联系起来的函数g(即g(η)=E[T(y);η])称为标准响应函数(canonical response function)，它的逆函数g-1称为标准关联函数(canonical link function)。 Softmax回归接下来我们来看一个更复杂的模型。在分类问题上，我们不止预测0和1两个值，假设我们预测的值有k个，即y∈{1,2,…,k}。那么我们就不能再使用伯努利分布了，我们考虑用多项式分布(Multinomial distribution)建模。 我们用φ1, φ2, … ,φk表示每个结果出现的概率，即P(y=k)=φk。由于所有结果概率之和为1，所以实际上k个参数中有1个是多余的，即： 为了使多项式分布能表示成指数分布族的形式，我们定义T(y)如下： 和我们之前的例子不一样，T(y)这次不等于y，而是一个k-1维的向量。我们用(T(y))i表示T(y)的第i个元素。 接下来我们引入指示函数(indicator function)：1{·}。如果参数表达式为真，则指示函数取值为1；表达式为假，指示函数取值为0，即1{True} = 1, 1{False} = 0。基于上述定义，我们可以得到：(T(y))i = 1{y = i}，进一步可得： 现在我们可以证明多项式分布也属于指数分布族，证明如下： 由η的表达式，我们可以得到η和φ的对应关系： 这个从η和φ的映射函数被称为softmax函数(softmax function)。有了softmax函数并结合假设3，我们可以求出p(y|x;θ)为： 这个k分类问题的算法被称为softmax回归(softmax regression)，它是逻辑回归更一般化的形式。 最后我们可以求出假设函数： 如果要求解参数θ，我们可以先求出它的对数似然函数l(θ)，然后用梯度上升或牛顿方法进行迭代。 总结 梯度上升和牛顿方法都能用于求解最大化l(θ)的问题，区别是牛顿方法收敛速度更快，但是它每次迭代的计算量也更大，当数据规模不大时总体上性能更优 指数分布族描述了一大类我们常见的概率分布，高斯分布、伯努利分布、多项式分布等都属于指数分布族 广义线性模型(GLM)描述了一种更通用的学习模型，最小二乘法和逻辑回归都可以从GLM推导出来 k分类问题可以用softmax回归建模，逻辑回归可以看作是softmax回归的特例(k=2) 参考资料 斯坦福大学机器学习课CS229讲义 pdf 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记2: 欠拟合与过拟合","date":"2018-01-29T14:55:48.000Z","path":"2018/01/29/machine-learning-underfitting-and-overfitting/","text":"线性回归的概率解释在解决线性回归问题时，我们为什么要使用最小二乘法作为代价函数？这个问题我们会通过概率统计来进行解释。 使用最小二乘法作为代价函数 假设对每个样本数据，输出值与预测值存在一定的误差ε(i)，误差可能来自未被建模的其他因素，也可能是随机的噪音。因而预测函数可写为 另外我们假设误差属于独立同分布(independently and identically distributed)，并且服从高斯分布N(0,σ2)，所以ε(i)的概率密度函数为 因此可推导出 P(y(i)|x(i);θ)表示：在θ为给定的参数的情况下，概率y(i)以x(i)为随机变量的概率分布，注意θ不是随机变量。 给定X(输入矩阵)和θ，Y(输出矩阵)的分布记为p(Y|X;θ)，这个概率的值我们定义为以θ为变量的似然函数(likelihood function) 由于每个误差值是独立分布的，所以 在θ作为参数的情况下，我们希望给定X时出现Y的概率是最大，因此问题变成最大化L(θ)。在求解最大化L(θ)的过程中，对L(θ)取对数将简化一些运算，因此我们最大化对数似然函数l(θ)： 上面的公式可以得出，最大化似然函数L(θ)等价于最小化代价函数J(θ)，这就是我们为什么取最小二乘法作为代价函数的原因。 局部加权线性回归如下左图显示了用线性函数y=θ0+θ1x拟合数据集的结果，由于数据集并不是一条直线，因此拟合效果不太理想。如果我们增加一个特征项x2，即用y=θ0+θ1x+θ2x2拟合数据集，那么得到的结果如中间所示。粗看起来，增加更多的特征项可以使拟合效果更好，然而事实上并非如此。如果我们把特征项增加到6项，即y= Σj∈[0,5]θjxj，我们得到的结果如右图所示。尽管这个曲线完美拟合整个数据集，但是我们很难说它能准确预测未知的新数据。我们把左图这种情况称为欠拟合(underfitting)，就是说模型没有很好地捕捉到数据特征，不能够很好地拟合数据；右图这种情况称为过拟合(overfitting)，就是说模型把数据学习得太彻底，以至于不能很好地预测新的数据。 欠拟合与过拟合 这里我们介绍一个新的方法称为局部加权线性回归(locally weighted linear regression)，它可以弥补普通线性回归模型欠拟合或者过拟合的问题。假设我们要预测x这个点对应的值，局部加权线性回归对x附近的每一个点赋予一定的权重，离x越近权重越大，离x越远权重越小。通过赋予权重，使得x附近的点对结果影响最大，离x很远的点对结果的影响可以忽略不计。因此代价函数表示如下，其中w(i)表示权重。 由上述对权重特性的描述，w(i)的图像应该是个钟形曲线。 通常我们定义w(i)的函数如下： 上式中的τ称为波长(bandwidth)，波长的大小取决了附近点的下降速率，参数根据对数据集的实验进行调整。 局部加权线性回归是一种非参数学习算法(non-parametric learning algorithm)，而之前我们学的普通线性回归是一种参数学习算法(parametric learning algorithm)。参数学习算法有固定的明确的参数，参数一旦确定，就不会改变了，我们不需要保留训练集中的训练样本。而非参数学习算法每进行一次预测，需要重新计算数据，因此需要保留训练数据。当训练数据较多时，非参数学习算法需要占用更多的存储空间。 逻辑回归现在我们开始讨论分类(classification)问题。分类问题和回归问题很类似，只不过预测的y值从连续值变成了离散值。我们先从最简单的二分类(binary classification)问题开始讨论，此时y值只有0和1两个取值。0被称为负类(negative class)，1被称为正类(positive class)，有时也会用符号-和+标记。给定x(i)，对应的y(i)值也被称为训练集的标签(label)。 一个二分类的例子是，通过给定肿瘤的大小(x(i))来预测是否为恶性肿瘤(y(i))。我们先用之前线性回归的方法求解这个问题，如下图所示，从结果上看线性回归的效果并不好。 直觉上看，hθ(x)的取值应该是介于0到1之间的。为了达到这一点，通常我们选取hθ(x)如下： 其中g(z)被称为逻辑函数(logistic function)或者sigmoid函数(sigmoid function)。它的图形如下所示： g(z)的值域在0到1之间，当z趋向正无穷时，g(z)趋向于1；当z趋向负无穷是，g(z)趋向于0。g(z)还有另外一个有用的特性，g(z)对z的导数可以用其自身来表示，具体推导如下： 那么对于这样一个逻辑回归模型，我们如何选取θ进行拟合呢？套用之前极大似然估计的思想，我们为这个模型赋予一些概率假设： 这两个式子可以简化成一个： 其似然函数L(θ)为： 对数似然函数l(θ)为： 如何最大化l(θ)呢？类似于在线性回归里求代价函数最小值是用的梯度下降法，我们可以用梯度上升法求函数的最大值。因此θ的每次迭代如下： 对l(θ)进行求导： 所以我们得到梯度上升法则： 这个迭代规则和线性回归的最小均方算法(LMS)看上去非常类似，但它们并不是同一个算法，因为现在的hθ(x)是一个非线性函数。然而它们都拥有相似的形式，这究竟是巧合还是有更深层次的原因呢？这个我们后面会讲到。 感知器学习算法最后我们再简短地介绍一个新的算法。之前我们选取sigmoid函数作为hθ(x)，如果我们换成另外一个函数： 然后用同样的迭代规则： 这样我们得到的算法称为感知器学习算法(perceptron learning algorithm)。在上世纪60年代，感知器(perceptron)被认为是神经网络组成单元的一个粗糙的模型，这个我们后续会详细展开。 总结 线性回归的概率解释：最大化似然函数等价于最小化代价函数，这就是我们为什么取最小二乘法作为代价函数的原因 为了避免普通线性回归欠拟合和过拟合的问题，可以采用局部加权线性回归方法，通过赋予权重来强化离x近的点的结果，弱化离x远的点的结果 局部加权线性回归是一种非参数学习算法，普通线性回归是一种参数学习算法 二分类问题通常取hθ(x)为sigmoid函数，其迭代规则与线性回归的规则形式相似 参考资料 Coursera机器学习课程讲义 Week 3 Lecture Notes 斯坦福大学机器学习课CS229讲义 pdf 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"机器学习笔记1: 线性回归","date":"2018-01-01T05:38:16.000Z","path":"2018/01/01/machine-learning-linear-regression/","text":"监督学习与非监督学习机器学习是指给定一些训练数据，使机器能够利用它们分析未知数据。任何机器学习问题都可以分为两类：监督学习(Supervised Learning)和非监督学习(Unsupervised Learning)。这两类的区别在于：监督学习的训练数据有特征有标签，而非监督学习的训练数据没有。 监督学习问题一般是指给定输入预测输出，根据输出值的不同可以分为两类：回归(regression)和分类(classification)。回归预测的是连续值，分类预测的是离散值。 举例来说，给定房子的面积来预测房价是一个回归问题，因为房价是个连续值。如果把它改成预测房价是否超过某个阈值，那么这是一个离散问题，因为输出是个“是”或“否”的离散值。同理，给定一个人的图片预测TA的年龄是个回归问题，预测TA的性别是个分类问题。 而非监督学习问题在给定输入时，不知道预测的结果长什么样子，我们是从一堆数据里推导出其中的结构。 非监督学习最常见的应用是聚类(clustering)。举例来说，给定《美国经济》的1000篇文章，按照不同主题进行自动分类。另一个非聚类的典型例子是鸡尾酒会效应，指的是在一个嘈杂的鸡尾酒会环境中谈话中，尽管周围噪音很多，你仍能分辨出朋友对你说话的声音。 线性回归让我们先从监督学习中最简单的一个问题开始，假设我们有一个数据集如下，我们假设房价受住房面积的影响。 住房面积(英尺2) 房价(1000$) 2104 400 1600 330 2400 369 1416 232 3000 540 … … 我们的目标是对给定数据集学习出一个函数h: x → y，使得对每个输入x，h(x)都能很好的预测出输出y。由于历史原因，我们把h称为假设函数(Hypothesis Function)。下图描述了这一过程： 假设函数 我们需要对假设函数进行建模，最简单的方式是将它视为线性函数，因而可表示成： 其中θi称之为参数(parameter)或者权重(weight)。为了简化表述，我们定义θ0=1，那么： 其中最右面等式中的θ和x都是向量表示，n是输入变量的个数（在这个例子中n=1）。 那么我们应该如何选取θ，使得h(x)和y的误差最小。为此我们定义代价函数(cost function)如下： 其中x(i)这种上标表示方式是指第i个训练集的输入数据，y(i)是第i个训练集的输出值，m是训练集的个数。 梯度下降算法引入了代价函数后，我们的目标变成了：选择合适的θ，使得J(θ)最小。在这方面我们主要介绍梯度下降算法(Gradient Descent)。这个算法的主要思想是先选取一个初始点θ0，然后不断改变θ的值使得J(θ)变小，直到J(θ)收敛到最小值。特别的，为了使J(θ)变得最小，我们选择下一个θ值时应该选择能使J(θ)下降最快的那个值，在数学上就是对J(θ)求导，具体来说下一个选取的θ值就是： 其中α是学习率(learning rate)，它会影响梯度下降的幅度。在每次迭代中，可以选取不同的α值。下图是梯度下降算法的图示，在选取初始点后，每次都按下降速率最快的方式寻找下一个点，直到找到最低点。 梯度下降算法图示 我们将J(θ)展开进行推导，由此得到： 因而迭代规则更新为： 这个规则被称为最小均方算法(Least Mean Squares，缩写为LMS)或者Widrow-Hoff算法。 这个算法在每次迭代时都要计算一遍训练集的数据，因而被称为批量梯度下降法(Batch Gradient Descent)。当训练集数据量很大时，计算速度将变得很慢。为了解决这个问题，我们可以在每次迭代时随机选取训练集数据的一部分来代替整体，这种方法称之为随机梯度下降法(Stochastic Gradient Descent)。随机梯度下降法由于只选取了部分样本数据，因此迭代过程会比较不稳定，虽然每次迭代不一定按着全体最优解靠近，但整体上趋于全体最优解。 正规方程梯度下降法求解的缺点是需要很多次迭代，是否存在更好的方法呢。正规方程(Normal Equation)就是一个不需要进行迭代就能求解的方法，其公式如下： 其中X和y定义如下，XT是矩阵X的转置。 这个公式证明需要大量线性代数的知识，详细证明可以查阅参考资料。下表给出了梯度下降和正规函数两个算法的对比。 梯度下降 正规函数 需要选择学习率α 不需要选择学习率α 需要很多次迭代 不需要迭代 O(kn2) O(n3)，需要计算XTX的逆矩阵 n很大时也能正常工作 n很大时计算很慢 在实践中，当n&gt;=10000时不适合用正规函数，推荐改用梯度下降算法。 另外正规方程还有一个问题，就是XTX可能是不可逆的。不可逆的可能原因是我们使用了冗余的特征(比如两个特征线性相关)或者使用了太多的特征(比如特征数超过了样本数)。解决方法是删除一些多余的特征。 总结 机器学习问题可以分为监督学习和非监督学习，区别在于训练数据是否有特征 监督学习问题根据预测值的不同分为两类：预测值是连续值的叫回归，预测值是离散值的叫分类 最简单的回归模型是线性回归，求解线性回归的两个方法是：梯度下降和正规方程 当训练数据量较大时(n&gt;=10000)时推荐用梯度下降，数据量较小时用正规函数 参考资料 Coursera机器学习课程讲义 1 2 斯坦福大学机器学习课CS229讲义 pdf 网易公开课：机器学习课程 双语字幕视频","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://www.secondplayer.top/tags/机器学习/"}]},{"title":"从SQLAlchemy的“缓存”问题说起","date":"2017-11-21T15:37:21.000Z","path":"2017/11/21/sqlalchemy-cache/","text":"问题描述最近在排查一个问题，为了方便说明，我们假设现在有如下一个API： 1234567891011@app.route(\"/sqlalchemy/test\", methods=['GET'])def sqlalchemy_test_api(): data = &#123;&#125; # 获取商品价格 product = Product.query.get(1) data['old_price'] = product.present_price # 休眠10秒，等待外部修改价格 time.sleep(10) product = Product.query.get(1) data['new_price'] = product.present_price return jsonify(status='ok', data=data) 这里我们的后台使用了Flask作为服务端框架，SQLAlchemy作为数据库ORM框架。Product是一张商品表的ORM模型，假设原来id=1的商品价格为10，在程序休眠的10秒内价格被修改为20，那么你觉得返回的结果是多少？ old_price显然是10，那么new_price呢？讲道理的话由于外部修改价格为20了，同时程序在sleep后立刻又query了一次，你可能觉得new_price应该是20。但结果并不是，真实测试的结果是10，给人感觉就像是SQLAlchemy“缓存”了上一次的结果。 另外在测试的过程还发现一个现象，虽然在第一次API调用时两个price都是10，但是在第二次调用API时，读到的price是20。也就是说，在一个新的API开始时，之前“缓存”的结果被清除了。 SQLAlchemy的session状态管理之前我们提出了一个猜测：第二次查询是否“缓存”了第一次查询。为了验证这个猜想，我们可以把SQLALCHEMY_ECHO这个配置项打开，这是个全局配置项，官方文档定义如下： 配置项 说明 SQLALCHEMY_ECHO If set to True SQLAlchemy will log all the statements issued to stderr which can be useful for debugging. 在这个配置项打开的情况下，我们可以看到查询语句输出到终端下。我们再次调用API，可以发现第一次查询会输出类似SELECT * FROM product WHERE id = 1的语句，而第二次查询则没有这样的输出。如此看来，SQLAlchemy确实缓存了上次的结果，在第二次查询的时候直接使用了上次的结果。 实际上，当执行第一句product = Product.query.get(1)时，product这个对象处于持久状态(persistent)了，我们可以通过一些工具看到ORM对象目前处于的状态。详细的状态列表可在官方文档中找到。 123456789&gt;&gt;&gt; from sqlalchemy import inspect&gt;&gt;&gt; insp = inspect(product)&gt;&gt;&gt; insp.persistentTrue&gt;&gt;&gt; product.__dict__&#123; 'id': 1, 'present_price': 10, '_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x1106a3350&gt;,&#125; 为了清除该对象的缓存，程度从低到高有下面几种做法。expire会清除对象里缓存的数据，这样下次查询时会直接从数据库进行查询。refresh不仅清除对象里缓存的数据，还会立刻触发一次数据库查询更新数据。expire_all的效果和expire一样，只不过会清除session里所有对象的缓存。flush会把所有本地修改写入到数据库，但没有提交。commit不仅把所有本地修改写入到数据库，同时也提交了该事务。 12345db.session.expire(product)db.session.refresh(product)db.session.expire_all()db.session.flush()db.session.commit() 我们对这几种方法依次做实验，结果发现这5个操作都会让下次查询直接从数据库进行查询，但只有commit会读到最新的price。那这个又是什么原因呢，我们已经强制每次查询走数据库，为何还是读到“缓存”的数据。这个就要用数据库的事务隔离机制来解释了。 事务隔离在数据库系统中，事务隔离级别(isolation level)决定了数据在系统中的可见性。隔离级别从低到高分为四种：未提交读(Read uncommitted)，已提交读(Read committed)，可重复读(Repeatable read)，可串行化(Serializable)。他们的区别如下表所示。 隔离级别 脏读 不可重复读 幻读 未提交读(RU) 可能 可能 可能 已提交读(RC) 不可能 可能 可能 可重复读(RR) 不可能 不可能 可能 可串行化 不可能 不可能 不可能 脏读(dirty read)是指一个事务可以读到其他事务还未提交的数据。不可重复读(non-repeatable read)是指在一个事务中同一行被读取了多次，可以读到不同的值。幻读(phantom read)是指在一个事务中执行同一个语句多次，读到的数据行发生了改变，即可能行数增加了或减少了。 前面提到的问题其实就涉及到不可重复读这个特性，即在一个事务中我们query了product.id=1的数据多次，但读到了重复的数据。对于MySQL来说，默认的事务隔离级别是RR，通过上表我们可知RR是可重复读的，因此可以解释这个现象。 事务A 事务B BEGIN; BEGIN; SELECT present_price FROM product WHERE id = 1; /* id=1的商品价格为10 */ UPDATE product SET present_price = 20 WHERE id = 1; /* 修改id=1的商品价格为20 */ COMMIT; SELECT present_price FROM product WHERE id = 1; /* 再次查询id=1的商品价格 */ COMMIT; 对于前面的问题，我们可以把两个事务的执行时序图画出来如上所示。因此为了使第二次查询得到正确的值，我们可以把隔离级别设为RC，或者在第二次查询前进行COMMIT新起一个事务。 Flask-SQLAlchemy的自动提交前面还遗留一个问题没有搞清楚：在一个新的API开始时，之前“缓存”的结果似乎被清除了。由于打开了SQLALCHEMY_ECHO配置项，我们可以观察到每次API结束的时候都会自动触发一次COMMIT，而正是这个自动提交清空了所有的“缓存”。通过查找源代码，我们发现是下面这段代码在起作用： 1234567@teardowndef shutdown_session(response_or_exc): if app.config['SQLALCHEMY_COMMIT_ON_TEARDOWN']: if response_or_exc is None: self.session.commit() self.session.remove() return response_or_exc 如果配置项SQLALCHEMY_COMMIT_ON_TEARDOWN为True，那么首先触发COMMIT，最后统一执行session.remove()操作，即释放连接并回滚事务操作。 有意思的是，这个配置项在Flask2.0版本的Changelog中被移除了。 Flask2.0 Changelog 关于删除的原因，作者在stackoverflow的一个帖子里进行了说明。这个帖子同时也解释了为什么在我们的生产环境中经常报这个错误：InvalidRequestError: This session is in &#39;prepared&#39; state; no further SQL can be emitted within this transaction.，而且只有重启才能解决问题。有兴趣的同学可以深入阅读一下。 总结在MySQL的同一个事务中，多次查询同一行的数据得到的结果是相同的，这里既有SQLAlchemy本身“缓存”结果的原因，也受到数据库隔离级别的影响。如果要强制读取最新的结果，最简单的办法就是在查询前手动COMMIT一次。根据这个原则，我们可以再仔细阅读下自己项目中的代码，看看会不会有一些隐藏的问题。","tags":[{"name":"Flask","slug":"Flask","permalink":"http://www.secondplayer.top/tags/Flask/"},{"name":"SQLAlchemy","slug":"SQLAlchemy","permalink":"http://www.secondplayer.top/tags/SQLAlchemy/"}]},{"title":"迁移博客到阿里云","date":"2017-10-31T15:00:38.000Z","path":"2017/10/31/migrate-to-aliyun-ecs/","text":"起因去年在AWS上搭建的博客已经过去一年多了，之前在使用Hexo搭建个人静态博客这篇文章中提到，使用AWS可以免费使用一年的VPS，然而一年到了后发现一个月要收费12.94美元，感觉实在性价比不高。听说阿里云在2016年开始进军海外业务，所以趁这次机会迁移过去。于是在官网上购买了美国西部（硅谷）节点的服务器，目前在双11活动期间处于优惠价，有兴趣的朋友可以趁现在入手试一下。 购买阿里云ECS ECS环境配置购买完服务器后就开始配置环境了。首先是登录服务器，默认是密码方式登录。然而每次输入密码实在是太麻烦了，建议使用密钥方式登录，在ECS后台-网络和安全-密钥对里创建一个新的密钥对，然后将其与你的实例绑定，之后就可以用私钥登录了。注意密钥对创建完成后一定要马上下载私钥，因为阿里云只给你一次下载私钥的机会，并且不要将私钥泄露给别人。 登录到服务器之后开始安装环境，在此之前需要检查一下服务器是否能访问外网。如果无法访问外网，需要到ECS后台-网络和安全-安全组里新建安全组，给安全组配置默认规则，默认规则的出方向即为允许访问任意ip的任意端口。这个安全组后面还会用到，如果你想开放一个自定义端口允许外网访问，也需要新建一个安全组并配置相应规则。 配置安全组规则 迁移博客一切准备就绪后开始迁移博客。由于hexo是静态博客，所以只需把相应的静态文件拷贝的新机器上即可。这里列一下遇到的坑以及一些升级改动。 全局安装hexo报错旧服务器上的node版本是v4.4.5，转眼一年过去了，最新版本是v8.4.0。在新版本下执行npm install hexo-cli -g安装hexo会有报错，解决办法详见官方issues，简而言之就是先执行一句npm config set unsafe-perm true再安装即可。 升级主题我的博客一直在使用这个Material Design风格的主题，名叫indigo。在一年内这个主题也有了较大的更新，升级之后界面变得更简洁了，优化了分享功能，增加了赞赏功能。升级的话也很简单，直接将代码更新到最新，按照文档更新配置即可。 评论系统切换旧博客使用的评论系统是多说，然而这家公司业务调整，已经关闭该系统了。知乎上有很多关于替代方案的讨论)，最终我选择了用gitment作为新博客的评论系统。这套评论系统最大的特点是基于GitHub Issues的评论系统，主要面向程序员群体。使用上也很方便，而且indigo主题已经支持gitment，所以只需简单配置几个参数就能使用了。 总结整个迁移步骤，主要在熟悉阿里云后台配置上花的时间最多。由于AWS是行业先行者，可以看得出阿里云的后台功能有点仿照AWS的意思，但可能是功能太多的缘故，给人感觉布局很拥挤。不管怎样，博客还是成功迁移了，在阿里云海外服务器上搭建科学上网工具也很流畅。 最后打个广告，如果有兴趣购买阿里云的相关产品可以使用这个推广链接，点击链接可以领取优惠券。","tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.secondplayer.top/tags/Hexo/"},{"name":"阿里云","slug":"阿里云","permalink":"http://www.secondplayer.top/tags/阿里云/"}]},{"title":"重构: 改善既有代码的设计","date":"2017-09-18T16:12:24.000Z","path":"2017/09/19/refactoring-book/","text":"重构这本书由著名的世界软件开发大师Martin Fowler编写，是软件开发领域的经典书籍。书中的部分内容在refactoring.com上也有提及。 重构: 改善既有代码的设计 什么是重构视上下文不同，重构有两个定义： 重构(名词)：对软件内部结构的一种调整，目的是在不改变软件可观察行为的前提下，提高其可理解性，降低其修改成本 重构(动词)：使用一系列重构手法，在不改变软件可观察行为的前提下，调整其结构 为什么要重构重构是个工具，它可以用于以下几个目的： 重构改进软件设计 重构使软件更容易理解 重构帮助找到bug 重构提高编程速度 何时重构不需要专门拨出时间进行重构，重构应该随时随地进行。你之所以重构，是因为你想做别的什么事，而重构可以帮助你把那些事做好。 事不过三，三则重构 添加功能时重构 修补错误时重构 复审代码时重构 何时不该重构 当既有代码实在太混乱，重构不如重写来得简单 当项目已接近最后期限，应该避免进行重构，因为已经没有时间了 代码的坏味道「如果尿布臭了，就换掉它」。代码的坏味道指出了重构的可能性。 重复代码 (Duplicated Code) 过长函数 (Long Method) 过大的类 (Large Class) 过长参数列 (Long Parameter List) 发散式变化 (Divergent Change) switch语句 (Switch Statements) 中间人 (Middle Man) 异曲同工的类 (Alternative Classes with Different Interfaces) 过多的注释 (Comments) … 构筑测试体系重构的基本技巧「小步前进，频繁测试」已经得到了多年的实践检验。因此如果你想进行重构，首要前提就是拥有一个可靠的测试体系。 常用重构方法提炼函数 (Extract Method) 当我看见一个过长的函数或者一段需要注释才能让人理解用途的代码，我就会将这段代码放进一个独立函数中 1234567void printOwing() &#123; printBanner(); //print details System.out.println (\"name: \" + _name); System.out.println (\"amount \" + amount);&#125; 123456789void printOwing() &#123; printBanner(); printDetails(amount);&#125;void printDetails (double amount) &#123; System.out.println (\"name: \" + _name); System.out.println (\"amount \" + amount);&#125; 引入解释性变量 (Introduce Explaining Variable) 表达式有可能非常复杂而难以阅读。这种情况下，临时变量可以帮助你将表达式分解为比较容易管理的形式。 123456if ((platform.toUpperCase().indexOf(\"MAC\") &gt; -1) &amp;&amp; (browser.toUpperCase().indexOf(\"IE\") &gt; -1) &amp;&amp; wasInitialized() &amp;&amp; resize &gt; 0)&#123; // do something&#125; 123456final boolean isMacOs = platform.toUpperCase().indexOf(\"MAC\") &gt; -1;final boolean isIEBrowser = browser.toUpperCase().indexOf(\"IE\") &gt; -1;final boolean wasResized = resize &gt; 0;if (isMacOs &amp;&amp; isIEBrowser &amp;&amp; wasInitialized() &amp;&amp; wasResized) &#123; // do something&#125; 分解临时变量 (Split Temporary Variable) 如果临时变量承担多个责任，它就应该被替换(分解)为多个临时变量，每个变量只承担一个责任。同一个临时变量承担两件不同的事情，会令代码阅读者糊涂。 1234double temp = 2 * (_height + _width);System.out.println (temp);temp = _height * _width;System.out.println (temp); 1234final double perimeter = 2 * (_height + _width);System.out.println (perimeter);final double area = _height * _width;System.out.println (area); 移除对参数的赋值 (Remove Assignments to Parameters) 我之所以不喜欢(对参数赋值)这样的做法，因为它降低了代码的清晰度，而且混淆了按值传递和按引用传递这两种参数传递方式。当然，面对那些使用「输出式参数」(output parameters)的语言，你不必遵循这条规则。不过在那些语言中我会尽量少用输出式参数。 12345int discount (int inputVal, int quantity, int yearToDate) &#123; if (inputVal &gt; 50) &#123; inputVal -= 2; &#125;&#125; 123456int discount (int inputVal, int quantity, int yearToDate) &#123; int result = inputVal; if (inputVal &gt; 50) &#123; result -= 2; &#125;&#125; 提炼类 (Extract Class) 某个类做了应该由两个类做的事。此时你需要考虑哪些部分可以分离出去，并将它们分离到一个单独的类中。 提炼类 移除中间人 (Remove Middle Man) 每当客户要使用受托类的新特性时，你就必须在服务端添加一个简单委托函数。随着受托类的特性(功能)越来越多，这一过程会让你痛苦不已。服务类完全变成了一个“中间人”，此时你就应该让客户直接调用受托类。 移除中间人 以字面常量取代魔法数 (Replace Magic Number with Symbolic Constant) 所谓魔法数(magic number)是指拥有特殊意义，却又不能明确表现出这种意义的数字。如果你需要在不同的地点引用同一个逻辑数，魔法数会让你烦恼不已，因为一旦这些数发生改变，你就必须在程序中找到所有魔法数，并将它们全部修改一遍，这简直就是一场噩梦。就算你不需要修改，要准确指出每个魔法数的用途，也会让你颇费脑筋。 123double potentialEnergy(double mass, double height) &#123; return mass * 9.81 * height;&#125; 1234double potentialEnergy(double mass, double height) &#123; return mass * GRAVITATIONAL_CONSTANT * height;&#125;static final double GRAVITATIONAL_CONSTANT = 9.81; 分解条件表达式 (Decompose Conditional) 程序之中，复杂的条件逻辑是最常导致复杂度上升的地点之一。你必须编写代码来检查不同的条件分支、根据不同的分支做不同的事，然后你很快就会得到一个相当长的函数。对于条件逻辑，将每个分支条件分解成新函数可以给你带来更多好处：可以突出条件逻辑，更清楚地表明每个分支的作用，并且突出每个分支的原因。 123if (date.before (SUMMER_START) || date.after(SUMMER_END)) charge = quantity * _winterRate + _winterServiceCharge;else charge = quantity * _summerRate; 123if (notSummer(date)) charge = winterCharge(quantity);else charge = summerCharge (quantity); 合并条件表达式 (Consolidate Conditional Expression) 之所以要合并条件代码，有两个重要原因。首先，合并后的条件代码会告诉你“实际上只有一次条件检查，只不过有多个并列条件需要检查而已”，从而使这一次检查的用意更清晰。其次，这项重构往往可以为你使用提炼函数(Extract Method)做好准备。将检查条件提炼成一个独立函数对于厘清代码意义非常有用，因为它把描述“做什么”的语句换成了“为什么这样做”。 12345double disabilityAmount() &#123; if (_seniority &lt; 2) return 0; if (_monthsDisabled &gt; 12) return 0; if (_isPartTime) return 0; // compute the disability amount 123double disabilityAmount() &#123; if (isNotEligableForDisability()) return 0; // compute the disability amount 合并重复的条件片段 (Consolidate Duplicate Conditional Fragments) 有时你会发现，一组条件表达式的所有分支都执行了相同的某段代码。如果是这样，你就应该将这段代码搬移到条件表达式外面。这样，代码才能更清楚地表明哪些东西随条件的变化而变化、哪些东西保持不变。 12345678if (isSpecialDeal()) &#123; total = price * 0.95; send();&#125;else &#123; total = price * 0.98; send();&#125; 12345if (isSpecialDeal()) total = price * 0.95;else total = price * 0.98;send(); 移除控制标记 (Remove Control Flag) 人们之所以会使用这样的控制标记，因为结构化编程原则告诉他们：每个子程序只能有一个入口和一个出口。我赞同“单一入口”原则（而且现代编程语言也强迫我们这样做），但是“单一出口”原则会让你在代码中加入讨厌的控制标记，大大降低条件表达式的可读性。这就是编程语言提供break语句和continue语句的原因：用它们跳出复杂的条件语句。去掉控制标记所产生的效果往往让你大吃一惊：条件语句真正的用途会清晰得多。 12345678910111213141516boolean checkSecurity(String[] people) &#123; boolean found = false; for (int i = 0; i &lt; people.length; i++) &#123; if (!found)&#123; if (people[i].equals(\"Don\")) &#123; sendAlert(); found = true; &#125; if (people[i].equals(\"John\")) &#123; sendAlert(); found = true; &#125; &#125; &#125; return found;&#125; 123456789101112131415boolean checkSecurity(String[] people) &#123; for (int i = 0; i &lt; people.length; i++) &#123; if (!found)&#123; if (people[i].equals(\"Don\")) &#123; sendAlert(); return true; &#125; if (people[i].equals(\"John\")) &#123; sendAlert(); return true; &#125; &#125; &#125; return false;&#125; 以卫语句取代嵌套条件表达式 (Replace Nested Conditional with Guard Clauses) 如果条件表达式的两条分支都是正常行为，就应该使用形如if…else…的条件表达式；如果某个条件极其罕见，就应该单独检查该条件，并在该条件为真时立刻从函数中返回。这样的单独检查常常被称为“卫语句”(guard clauses)。 这个方法的精髓是：给某一条分支以特别的重视。它告诉阅读者：这种情况很罕见，如果它真地发生了，请做一些必要的整理工作，然后退出。 “每个函数只能有一个入口和一个出口”的观念，根深蒂固于某些程序员的脑海里。现今的编程语言都会强制保证每个函数只有一个入口，至于“单一出口”规则，其实不是那么有用。保持代码清晰才是最关键的：如果单一出口能使这个函数更清晰易读，那么就使用单一出口；否则就不必这么做。 123456789101112double getPayAmount() &#123; double result; if (_isDead) result = deadAmount(); else &#123; if (_isSeparated) result = separatedAmount(); else &#123; if (_isRetired) result = retiredAmount(); else result = normalPayAmount(); &#125;; &#125; return result;&#125;; 123456double getPayAmount() &#123; if (_isDead) return deadAmount(); if (_isSeparated) return separatedAmount(); if (_isRetired) return retiredAmount(); return normalPayAmount();&#125;; 扩展阅读：关于如何重构嵌套条件表达式，可以阅读如何重构“箭头型”代码，这篇文章更深层次地讨论了这个问题。 将查询函数和修改函数分离 (Separate Query from Modifier) 下面是一条好规则：任何有返回值的函数，都不应该有看得到的副作用。 如果你遇到一个“既有返回值又有副作用”的函数，就应该试着将查询动作从修改动作中分割出来。 将查询函数和修改函数分离","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://www.secondplayer.top/tags/读书笔记/"},{"name":"重构","slug":"重构","permalink":"http://www.secondplayer.top/tags/重构/"}]},{"title":"常见推荐系统介绍","date":"2017-09-07T16:07:37.000Z","path":"2017/09/08/recommendation-system-book/","text":"本文主要是对项亮的推荐系统实践部分章节进行了一些总结，先从什么是推荐系统开始讲起，然后介绍了评测推荐系统的指标和方法，最后介绍了常见的推荐系统算法。 《推荐系统实践》封面 什么是推荐系统随着信息技术和互联网的快速发展，人们逐渐从信息匮乏的时代走入了信息过载的时代。每天都有海量的信息被生产出来，用户如何从中找到自己感兴趣的内容变得越来越困难，内容生产者也在想方设法让自己生成的内容从海量信息中脱颖而出。为了解决信息过载的问题，历史上出现过的代表方案有分类目录和搜索引擎，这两者都要求用户明确知道自己需要的内容关键词。而推荐系统不需要用户提供明确的需求，而是通过分析用户的历史行为给用户的兴趣建模，从而主动给用户推荐能够满足它们兴趣的内容。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户，帮助用户发现那些他们感兴趣但很难发现的商品。 推荐系统的应用在互联网的各类网站中都可以看到推荐系统的应用，尽管不同网站使用的技术不同，但总的来说几乎所有的推荐系统应用都是由前台的展示页面、后台的日志系统以及推荐算法系统构成。 电子商务：淘宝、京东、亚马逊 电影/视频：Netflix、YouTube、爱奇艺 音乐：Pandora、网易云音乐、豆瓣FM 社交网络：Facebook、Twitter、LinkedIn、新浪微博 个性化阅读：Digg、Flipboard、今日头条 基于位置的服务：Foursquare 个性化广告：Facebook Audience Network 推荐系统实验方法在推荐系统中，主要有三种评测推荐效果的实验方法：离线实验、用户调查、在线实验。 推荐系统评测指标 用户满意度：用户的主观感受，主要通过用户调查的方式获得，也可以间接从用户行为统计中得到。 预测准确度：度量一个推荐系统或推荐算法预测用户行为的能力。评分预测的预测准确度一般通过计算测试集和训练集的均方根误差(RMSE)和平均绝对误差(MAE)得到。TopN推荐的预测准确度一般通过计算测试集和训练集的准确率(precison)和召回率(recall)得到。 令rui是用户u对物品i的实际评分，r^ui是推荐算法给出的预测评分，T是测试集，那么：RMSE = sqrt(Σu,i∈T(rui-r^ui)2 / |T|)MAE = Σu,i∈T|rui-r^ui| / |T| 令R(u)是用户u在训练集上的推荐结果，T(u)是用户u在测试集上的行为结果，U是用户集合，那么： Precision = Σu∈U|R(u) ∩ T(u)| / Σu∈U|R(u)| Recall = Σu∈U|R(u) ∩ T(u)| / Σu∈U|T(u)| 覆盖率：描述一个推荐系统对物品长尾的发掘能力。 假设用户集合为U，物品集合为I，推荐系统给每个用户推荐一个长度为N的物品列表R(u)，那么：Coverage = |∪u∈UR(u)| / |I| 多样性：为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域。 新颖性：是指给用户推荐那些他们以前没听说过的商品。 惊喜度(serendipity)：如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高。 信任度：提高信任度的方法是给出合理的推荐解释。 实时性：推荐系统需要实时地更新推荐列表来满足用户新的行为变化，并且需要能够将新加入系统的物品推荐给用户。 健壮性(robust)：衡量一个推荐系统抗击作弊的能力。 在众多指标中，作者认为：对于可以离线优化的指标，应该在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。 常见推荐系统算法推荐系统是联系用户和物品的媒介，而推荐联系用户和物品的方式主要有3种，如下图所示。 3种联系用户和物品的推荐系统 第一种方法，首先找到用户喜欢的物品，然后找到与这些物品相似的物品推荐给用户。基于这种方法可以给出如下的推荐解释：购买了该商品的用户也经常购买这些商品。这种方法通常被称为基于物品的协同过滤算法(item-based collaborative filtering)。第二种方法，首先找到和用户有相似兴趣的其他用户，然后推荐这些其他用户喜欢的物品。这种方法通常被称为基于用户的协同过滤算法(user-based collaborative filtering)。第三种方法，首先找到用户感兴趣的物品特征，然后推荐包含这些特征的物品。这种方法核心思想是通过隐含特征联系用户兴趣和物品，通常被称为隐语义模型算法(latent factor model)。 协同过滤算法个性化推荐系统的一个重要算法是基于用户行为分析，学术界一般将这种类型的算法称为协同过滤算法(collaborative filtering)。 顾名思义，协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤掉自己不感兴趣的物品，从而越来越满足自己的需求。 基于物品的协同过滤算法基于物品的协同过滤算法(以下简称ItemCF)，是目前业界应用最多的算法，最早由电子商务公司亚马逊提出。ItemCF算法给用户推荐那些和他们之前喜欢的物品相似的物品，它的主要步骤分为两步。 (1) 计算物品之间的相似度 (2) 根据物品的相似度和用户的历史行为给用户生成推荐列表 第一步计算相似度可用余弦相似度公式 令N(i)是喜欢物品i的用户集合，那么物品i和物品j的相似度可定义为： wij = |N(i) ∩ N(j)| / sqrt(|N(i)||N(j)|) 第二步计算用户对物品的兴趣，如下公式的含义是：和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。 令puj为用户u对物品j的兴趣，wji是物品j和物品i的相似度，rui是用户u对物品i的兴趣（对于隐反馈数据集，如果用户u对物品i有过行为，可简单令rui=1），S(j,K)是和物品j最相似的K个物品的集合，那么： puj = Σi∈N(u)∩S(j,K) wjirui 最后选取该用户兴趣值最高的N的物品作为推荐列表。 基于用户的协同过滤算法基于用户的协同过滤算法(以下简称UserCF)，是推荐系统中最古老的算法。UserCF算法先找到和他有相似兴趣的其他用户，然后把那些用户喜欢的、而他没有听说过的物品推荐给他，它的主要步骤分为两步。 (1) 找到和目标用户兴趣相似的用户集合 (2) 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户 第一步计算用户的兴趣相似度可用余弦相似度公式 令N(u)是用户u曾经有过正反馈的物品集合，那么用户u和用户v的相似度可定义为： wuv = |N(u) ∩ N(v)| / sqrt(|N(u)||N(v)|) 第二步计算用户对物品的兴趣 令pui为用户u对物品i的兴趣，wuv是用户u和用户v的相似度，rvi是用户v对物品i的兴趣（对于隐反馈数据集，如果用户v对物品i有过行为，可简单令rvi=1），S(u,K)是和用户u兴趣最相似的K个用户的集合，那么： pui = Σv∈N(i)∩S(u,K) wuvrvi 最后选取该用户兴趣值最高的N的物品作为推荐列表。 隐语义模型隐语义模型算法(以下简称LFM)，是最近几年推荐系统领域最为热门的研究话题。LFM算法的核心思想是通过隐含特征联系用户兴趣和物品，它的主要步骤分为三步。 (1) 对物品进行分类 (2) 确定用户对哪些类的物品感兴趣以及感兴趣的程度 (3) 对于给定的类，确定物品在这个类的权重，并且选择性地推荐给用户 关于如何给物品分类，一个简单方案是由编辑来手动分类，但这样存在很强的主观性和较大的工作量。为了解决这个困难，研究人员提出可以从用户数据出发，基于隐含语义分析技术(latent variable analysis)自动找到哪些类，然后进行个性化推荐。隐含语义分析技术有很多著名的模型和方法，比如pLSA、LDA、隐含类别模型、隐含主题模型、矩阵分解等。 LFM通过如下公式计算用户u对物品i的兴趣： Preferenceui = Σk∈[1,K] pu,kqi,k 其中pu,k度量了用户u的兴趣和第k个隐类的关系，而qi,k度量了第k个隐类和物品i的关系。这两个参数的计算需要一点最优化理论或者机器学习的知识，这里不多作介绍。 三种算法的优缺点比较 LFM是一种基于机器学习的算法，有较好的理论基础。ItemCF/UserCF是基于邻域的方法，更多的是一种基于统计的方法，没有学习过程。 假设有M个用户和N个物品，选取F个隐类。UserCF需要存储用户的相似度矩阵，存储空间是O(M*M)。ItemCF需要存储物品的相似度矩阵，存储空间是O(N*N)。LFM需要的存储空间是O(F*(M+N))。如果用户数很多，UserCF将会占据很大的内存。如果物品数很多，ItemCF将会占据很大的内存。LFM存储空间最少，这在M和N很大时可以很好地节省离线计算的内存。 假设有M个用户和N个物品和K条用户对物品的行为记录。那么，UserCF计算用户表的时间复杂度是O(N*(K/N)2)，而ItemCF计算物品表的时间复杂度是O(M*(K/M)2)。而对于LFM，如果用F个隐类，迭代S次，那么它的时间复杂度是O(K*F*S)。在一般情况下，LFM的时间复杂度要稍微高于UserCF和ItemCF，主要是因为该算法需要多次迭代。 ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果，但LFM无法提供这样的解释。 总结在互联网应用中可以看到大量推荐系统的应用，它主要解决了信息过载的问题，通过算法主动帮助用户找到自己感兴趣的内容。常见的推荐系统算法有三种，分别代表三种联系用户和物品的方式，它们是：基于物品的协同过滤算法(ItemCF)，基于用户的协同过滤算法(ItemCF)，隐语义模型算法(LFM)。三种方法各有优劣，需要根据实际场景选择合适的算法，通过不断优化指标找到最优算法。","tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"http://www.secondplayer.top/tags/推荐系统/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://www.secondplayer.top/tags/读书笔记/"}]},{"title":"使用redis的有序集合实现排行榜功能","date":"2017-07-23T05:43:36.000Z","path":"2017/07/23/redis-sorted-set/","text":"排行榜是业务开发中常见的一个场景，如何设计一个好的数据结构能够满足高效实时的查询，下面我们结合一个实际例子来讨论一下。 场景选手报名参加活动，观众可以对选手进行投票，每个观众对同一名选手只能投一票，活动期间最多投四票。后台需要提供如下接口： 接口1：返回TOP 10的选手信息及投票数 接口2：返回活动总参与选手数及总投票数 接口3：对于每个选手，返回自己的投票数，排名，距离上一名差的票数 基于数据库的方案首先需要一张表存储投票记录，一次投票就是一条记录。这张表相当于投票明细，判断每人只投一张票以及最多投四张表都依赖对这张表的查询。如果直接对这张表做TOP 10的查询，则需要根据选手id做聚合查询，这样每次查询必然耗时。为了优化查询，可以增加另一张排行榜表，用一个定时任务每隔一段时间对原表做聚合查询，然后将结果写进排行榜表里，表里包含投票数及排名的字段，这样查询TOP 10和排名的时候直接查这张表。引入另一张表加快了性能，但牺牲了实时性，活动说明里需加上类似“榜单数据每10分钟同步一次”的话来告知用户。 基于redis的方案对于排行榜的需求，redis有一个数据结构非常适合做这件事，那就是有序集合(sorted set)。 redis的有序集合相关命令有序集合和集合一样可以存储字符串，另外有序集合的成员可以关联一个分数(score)，这个分数用于集合排序。下面以投票为例说明常见的命令，vote_activity是有序集合的key。12345678910111213141516171819202122232425262728#给Alice投票redis&gt; zincrby vote_activity 1 Alice&quot;1&quot; #给Bob投票redis&gt; zincrby vote_activity 1 Bob&quot;1&quot;#给Alice投票redis&gt; zincrby vote_activity 1 Alice&quot;2&quot;#查看Alice投票数redis&gt; zscore vote_activity Alice&quot;2&quot;#获取Alice排名(从高到低，zero-based)redis&gt; zrevrank vote_activity Alice(integer) 0#获取前10名(从高到低)redis&gt; zrevrange vote_activity 0 91) &quot;Alice&quot;2) &quot;Bob&quot;#获取前10名及对应的分数(从高到低)redis&gt; zrevrange vote_activity 0 9 withscores1) &quot;Alice&quot;2) &quot;2&quot;3) &quot;Bob&quot;4) &quot;1&quot;#获取总参与选手数redis&gt; zcard vote_activity(integer) 2 接口实现回到最开始的场景，大部分需求都已经得到满足，还剩下两个数据需要单独说一下。接口2中的总投票数没有直接的接口获得，一种方法是先用ZRANGE遍历所有的key，然后对score进行求和，另一种方法是对总票数单独用一个数据结构存储。接口3的距离上一名差的票数，先用ZREVRANK获取自己排名，然后用ZREVRANGE获取上一排名的分数，最后用自己的分数减去上一名的分数即可，代码示例如下：12345678def get_next_step(redis_key, member): next_step = None score = redis.zscore(redis_key, member) rank = redis.zrevrank(redis_key, member) if rank &gt; 0: next_member = redis.zrevrange(redis_key, rank - 1, rank - 1, withscores=True) next_step = next_member[0][1] - score return next_step 另外如果两个key的score相同，排序逻辑是按照key的字母序排序。在有些情况下这个可能不满足实际要求，因此需要按实际情况重新设计key。比如如果要求同分数情况下按时间排序，那么key最好加上时间戳前缀。 redis与数据库的同步redis通常是作为缓存层加速查询的，如果数据没有做持久化则有概率会丢失数据。一个方案是用定时任务定时同步redis与数据库的数据，数据库里存储着原始数据，通过计算数据库的数据和redis做对比，可以修正由于redis不稳定导致的数据不一致。这里需要注意的是在同步过程时redis的数据有可能还在增长，因此最好先读redis的数据，然后记下时间，查询指定时间段里的数据库的数据，最后再用ZINCRBY增量修正redis数据，而不是直接用ZADD覆盖redis数据。 总结redis的有序集合是一个非常高效的数据结构，可以替代数据库里一些很难实现的操作。它的一个典型应用场景就是排行榜，通过ZRANK可以快速得到用户的排名，通过ZRANGE可以快速得到TOP N的用户列表，它们的复杂度都是O(log(N))，用来替代数据库查询可以大大提升性能。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.secondplayer.top/tags/Redis/"}]},{"title":"使用redis实现分布式锁","date":"2017-07-16T05:40:10.000Z","path":"2017/07/16/redis-distribution-lock/","text":"背景在类似秒杀这样的并发场景下，为了确保同一时刻只能允许一个用户访问资源，需要利用加锁的机制控制资源的访问权。如果服务只在单台机器上运行，可以简单地用一个内存变量进行控制。而在多台机器的系统上，则需要用分布式锁的机制进行并发控制。基于redis的一些特性，利用redis可以既方便又高效地模拟锁的实现。 一个简单方案让我们先从一个简单的实现说起，这里用到了redis的两个命令，SETNX和EXPIRE。如果lock_key不存在，那么就设置lock_key的值为1，并且设置过期时间；如果lock_key存在，说明已经有人在使用这把锁，访问失败。12345def acquire_lock(lock_key, expire_timeout=60): if redis.setnx(lock_key, 1): redis.expire(lock_key, expire_timeout) return True return False 逻辑上看似乎没有问题，但是考虑一下异常情况：如果setnx设置成功，但expire由于某些原因（比如超时）操作失败，那么这把锁就永远存在了，也就是所谓的死锁，后面的人永远无法访问这个资源。 利用时间戳取值的方案为了解决死锁，我们可以利用setnx的value来做文章。上例中的我们设的value是1，其实并没有派上用场。因此可以考虑将value设为当前时间加上expire_timeout，当setnx设置失败后，我们去读lock_key的value，并且和当前时间作比对，如果当前时间大于value，那么资源理当被释放。代码示例如下：123456789def acquire_lock(lock_key, expire_timeout=60): expire_time = int(time.time()) + expire_timeout if redis.setnx(lock_key, expire_time): redis.expire(lock_key, expire_timeout) return True redis_value = redis.get(lock_key) if redis_value and int(time.time()) &gt; int(redis_value): redis.delete(lock_key) return False 然而仔细推敲下这段代码仍然能发现一些问题。第一，这个方案依赖时间，如果在分布式系统中的时间没有同步，则会对方案产生一定偏差。第二，假设C1和C2都没拿到锁，它们都去读value并对比时间，在竞态条件(race condition)下可能产生如下的时序：C1删除lock_key，C1获得锁，C2删除lock_key，C2获得锁。这样C1和C2同时拿到了锁，显然是不对的。 改进后的方案幸运的是，redis里还有一个指令可以帮助我们解决这个问题。GETSET指令在set新值的同时会返回老的值，这样的话我们可以检查返回的值，如果该值和之前读出来的值相同，那么这次操作有效，反之则无效。代码示例如下：123456789101112def acquire_lock(lock_key, expire_timeout=60): expire_time = int(time.time()) + expire_timeout if redis.setnx(lock_key, expire_time): redis.expire(lock_key, expire_timeout) return True redis_value = redis.get(lock_key) if redis_value and int(time.time()) &gt; int(redis_value): expire_time = int(time.time()) + expire_timeout old_value = redis.getset(lock_key, expire_time) if int(old_value) == int(redis_value): return True return False 这个方案基本可以满足要求，除了有一个小瑕疵，由于getset会去修改value，在竞态条件下可能会被修改多次导致timeout有细微的误差，但这个对结果影响不大。 最终方案以上方案实现起来略显繁琐，但从redis 2.6.12版本开始有一个更为简便的方法。我们可以使用SET指令的扩展 SET key value [EX seconds] [PX milliseconds] [NX|XX] ，这个指令相当于对SETNX和EXPIRES进行了合并，因而我们的算法可以简化为如下一行：123def acquire_lock(lock_key, expire_timeout=60): ret = redis.set(lock_key, int(time.time()), nx=True, ex=expire_timeout): return ret 总结在redis 2.6.12版本之后我们可以用一个简单的SET命令实现分布式锁，而在此版本之前则需要将SETNX和GETSET配合使用一个较为繁琐的方案。简化后的方案对于开发者来说当然是好事，但通过学习这一演变过程我们会对问题有更深刻的印象。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.secondplayer.top/tags/Redis/"}]},{"title":"使用Hexo搭建个人静态博客","date":"2016-06-12T06:42:23.000Z","path":"2016/06/12/hexo-blog-setup/","text":"最近有时间折腾了一下建一个个人博客，在对比了几家之后，最终决定用Hexo作为框架，GitHub作为部署平台搭建博客。VPS选用的是AWS，新用户可以免费使用1年的EC2，足够用来体验了。 申请VPSVPS指的是虚拟服务器，国内推荐用阿里云，国外推荐用Linode, Digital Ocean, AWS。我选择的是AWS，主要有几个原因，一是因为新用户可以试用免费1年，二是因为公司用的就是AWS，对其各项操作比较熟悉，最后一个原因是选择一个国外服务器可以自己搭建ShadowSocks科学上网。 申请域名域名申请服务商，国内有万网，美橙，国外有GoDaddy, NameCheap。我选择的是NameCheap，主要因为价格因素。你要问国内的那些更便宜为啥不选？呵呵国内的情况你懂的。 DNS解析DNS解析推荐DNSPOD，业界良心，服务免费且强大。域名绑定前记得先到NameCheap控制台设置DNS解析到DNSPOD提供的两个免费DNS解析服务器，具体参考这里。 Hexo安装及配置前面把主机和域名搞定了，现在开始在主机上搭建博客了。提到博客，一般都会选用经典的WordPress搭建。不过现在越来越多的个人博客都采用静态博客框架，典型的如Hexo， Jekyll， Octopress。从流行度和技术栈的角度来看，我倾向于选择Hexo。Hexo是一个用Node.js搭建的博客框架，简单强大易上手。静态文件用Markdown编写，Hexo会根据静态文件自动生成网页。 安装依赖环境 安装Git 1$ sudo apt-get install git 安装Node.js 通常用nvm(Node.js Version Manager)安装Node环境安装必要环境1$ sudo apt-get install build-essential libssl-dev 下载nvm1$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh 查看可用版本1$ nvm ls-remote 选取最新版本，这里我们安装v4.4.5，并将其设为默认123$ nvm install 4.4.5$ nvm alias default 4.4.5$ nvm use default 安装Hexo 我们通过npm分别安装hexo客户端和服务端 12$ npm install -g hexo-cli$ npm install -g hexo-server 生成文章 初始化hexo环境 我们把hexo_blog作为博客目录名，首先初始化hexo 123$ hexo init ~/hexo_blog$ cd ~/hexo_blog$ npm install 修改配置文件_config.yml 配置Site, URL, Directory, Writing等基本信息，详细参考这篇配置文档这里建议设置default_layout为draft，这样默认生成文章在Draft里，确认后再发布到Public。 发布文章 新建文章，以名称first_post为例 1$ hexo new first-post 编辑文章，文章都存放在source目录下 1$ vim ~/hexo_blog/source/_drafts/first-post.md 发布文章，这将会把文章从draft移到post目录 1$ hexo publish first-post 运行服务 启动服务器，默认起在4000端口，成功后访问http://localhost:4000 预览效果 1$ hexo server 部署博客我们需要选择一个静态文件的托管平台，首选GitHub，国内可以考虑Coding（最近收购了GitCafe）。 创建GitHub Repository 参考这个步骤，创建一个名为hexo_static的repo，注意设置为Public 修改配置文件_config.yml，注意替换$username 1234deploy: type: git repo: https://github.com/$username/hexo_static.git branch: master 安装hexo git插件 1$ npm install hexo-deployer-git --save 部署 12$ hexo generate$ hexo deploy 按照提示输入用户名和密码，一切步骤完成后，所有文件都已生成并提交到Git上了 自动化整个自动化的思路是：运行该脚本，生成博客静态文件，通过hexo deploy实现自动提交到Git，然后通过本地更新代码，对关联的空分支进行git push操作，触发post-receive钩子，从而将静态文件同步到/var/www/hexo目录，而该目录正是Nginx将80端口转发到本地的路径。 初始化空仓库 1$ git init --bare ~/hexo_bare 创建git hooks 1$ vim ~/hexo_bare/hooks/post-receive 这里我们用到了post-receive这个钩子，当一个本地仓库执行git push后会触发。post-receive具体内容为 123#!/bin/bashgit --work-tree=/var/www/hexo --git-dir=/home/$USER/hexo_bare checkout -f 将空仓库关联到主仓库 123$ git clone https://github.com/$username/hexo_static.git ~/hexo_static $ cd ~/hexo_static$ git remote add live ~/hexo_bare 创建自动化脚本 1$ vim ~/hexo_blog/hexo_git_deploy.sh 脚本内容为 1234567#!/bin/bashhexo cleanhexo generate hexo deploy( cd ~/hexo_static ; git pull ; git push live master) Nginx配置 创建/var/www/hexo目录，稍后会将Nginx的请求映射到该目录 123$ sudo mkdir -p /var/www/hexo$ sudo chown -R $USER:$USER /var/www/hexo$ sudo chmod -R 755 /var/www/hexo 编辑/etc/nginx/sites-available/default1$ sudo vim /etc/nginx/sites-available/default 配置Nginx将80端口的请求映射到/var/www/hexo目录下123456server &#123; listen 80 default_server; listen [::]:80 default_server ipv6only=on; root /var/www/hexo; index index.html index.htm;... 重启Nginx 1$ sudo service nginx restart 发布流程至此，我们可以总结下今后发布文章或更新博客的流程 1234$ hexo new my-post$ vim ~/hexo_blog/source/_draft/my-post.md$ hexo publish my-post$ hexo generate 接着运行hexo server，然后在http://localhost:4000 上预览效果，如果不满意则继续修改my-post.md（此时在_post目录下），重新生成文件（hexo generate），再预览直到可以发布为止 而最终对外发布，我们只需要敲下一行命令就完成了 1$ ~/hexo_blog/hexo_git_deploy.sh 其他 主题 默认hexo的主题是landscape，如果你想与众不同的话，可以用下别的主题或者自定义主题。官方收录的请点击这里，我选择的是indigo，主要看中的是他的Material Design风格 评论 常见的评论系统有Disqus，多说，友言等，我选择的是多说。接入非常简单，去网站上注册个账号，然后将示例代码插到网页中即可 统计 流量统计选择cnzz(现已被整合进Umeng+) 监控 可以接入监控宝 参考 Hexo Documentation How to Create a Blog with Hexo On Ubuntu 14.04","tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.secondplayer.top/tags/Hexo/"}]},{"title":"Hello World","date":"2016-06-10T16:00:00.000Z","path":"2016/06/11/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]